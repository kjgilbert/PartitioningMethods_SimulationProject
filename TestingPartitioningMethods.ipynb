{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating potential overfitting in partitioning methods for phylogenetic inference\n",
    "\n",
    "Even if information criteria like AIC, AICc, or BIC show better models with more partitions, the trees do not seem to be improving. Is this some sort of overfitting/overparameterizing?\n",
    "\n",
    "Aim is to test this using simulated trees\n",
    "\n",
    "\n",
    "From Jeremy's paper, the pipeline was:\n",
    "\n",
    "Each concatenated alignment was partitioned using PartitionFinder v2 (Lanfear et al. 2017) and MtPAN(3) (Nardi et al. 2014) using the Gap_script_charset.pl, Gap_script_physio.pl, and Gap_script.R scripts (Nardi et al. 2014). Moreover, the dataset was partitioned by its original OGs. For MtPAN, we used k=10 clusters, using 10,000 k-means seeds and 250 simulations. The initial data blocks fed to PartitionFinder were the genes of each of the datasets. We used a relaxed clustering search approach (Lanfear et al. 2014), the linked branch lengths option, and all protein models of evolution were considered, with BIC model selection.\n",
    "\n",
    "Partitioning schemes were inferred using RAxML and IQ-TREE. In RAxML (Stamatakis 2014), the tree search comprises of two main phases. During the first phase, the best candidate trees in terms of likelihood scores are re-evaluated, with the 20 best scoring trees saved. Beginning with an initial parsimony tree, the algorithm performs cycles of Subtree Pruning and Regrafting (SPR) moves, followed by branch length optimisations of the 20 best trees found during the SPRs. Here, each SPR cycle performs an SPR move on each of the subtrees and reinserts subtrees between a pre-determined rearrangement radius. If an improvement in likelihood is found, the tree is retained immediately. A more thorough rearrangement algorithm is then performed in order to find more likelihood improvements on the 20 best trees, in which branch lengths are optimised. In the second phase, candidate trees are evaluated more thoroughly, by altering the SPR radius. First, a smaller radius is used to apply SPRs, with the 20 best trees saved. If none of these 20 trees improve the tree, the radius in which SPRs are performed is extended, and so forth. IQ-TREE (Nguyen et al. 2015) uses a stochastic algorithm in order to find ML trees. It begins by generating 100 parsimony trees. From these, the 20 trees with the best ML score, and each with a unique topology, are selected. A stochastic hill climbing Nearest Neighbor Interchanges (NNI) algorithm is then used to find the best ML scoring trees. These trees are then further optimised in order to find the highest likelihood tree.\n",
    "\n",
    "RAxML_Default trees were inferred using automatic model selection and a gamma model for rate heterogeneity, using the PROTGAMMAAUTO flag. The BIC criterion was used for model selection. Rapid bootstrap was implemented, with 100 replicates.\n",
    "\n",
    "Similarly, for IQTREE_Default, the default settings, which implements ModelFinder (Kalyaanamoorthy et al. 2017) was implemented with a gamma model for rate heterogeneity. Ultrafast bootstraps was also implemented, with 1000 replicates (Hoang et al. 2018). Additionally, we inferred trees using ModelFinder without the constraint of a gamma model (IQTREE_FREERATE). These trees are included in the Supplementary materials.\n",
    "\n",
    "For RAxML_Partition, IQTREE_Partition, RAxML_MtPAN and IQTREE_MtPAN, the ModelFinder implementation in IQTREE was used in order to find the most suitable model for each partition. For the IQTREE methods, all possible models of evolution were included, including mixture models. For the RAxML implementations, only models found in RAxML were included for selection (i.e., mixture models were not included). A gamma rate of heterogeneity was selected, as well as linked branch length models.\n",
    "\n",
    "For both RAxML_PartitionFinder and IQTREE_PartitionFinder, a gamma rate of heterogeneity was used with the best scheme found by PartitionFinder. We also used edge-linked branch lengths when constructing phylogenetic trees. In the case of RAxML_PartitionFinder, 100 rapid bootstrap replicates were found. For IQTREE_PartitionFinder, 1000 ultrafast bootstrap replicates were inferred.\n",
    "\n",
    "In addition to partitioning models, we also assess the performance of a protein mixture model. We used the GHOST model implemented in IQ-TREE, an edge unlinked mixture model designed to deal with heterotachy.\n",
    "\n",
    "For our partitioned analysis, we used edge linked branch lengths. Edge unlinked branch lengths have 2n-3 extra parameters per additional partition (where n is the number of taxa), rather than a single extra parameter. Therefore, it is likely that edge unlinked models are over parameterised. The edge unlinked model was chosen for the IQTREE_GHOST method because it was used for its potential to account for heterotachy, which the edge unlinked model accounts for. For better comparison with the other methods in this study, the method should also be evaluated using the edge linked model.\n",
    "\n",
    "\n",
    "#### First, simulate (a range of?) trees with ALF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "alfsim inputfile\n",
    "\n",
    "# or can do bash this way:\n",
    "!alfsim inputfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then take the ALF output MSAs (mult. seq. align.s) and un-align them so that I can then try to build the trees from the unaligned sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingleLetterAlphabet() alignment with 30 rows and 398 columns\n",
      "AEE--TVLAV----------------------------------...KE- S001/00001\n",
      "AKQ--TVIGL----------------------------------...SF- S002/00001\n",
      "AQL--TGIDT----------------------------------...SW- S003/00001\n",
      "ADD--TGIGS----------------------------------...RA- S004/00001\n",
      "ASD--DGIRI----------------------------------...DI- S005/00001\n",
      "AKS--TGIRP----------------------------------...RP- S006/00001\n",
      "AV-----IRQ----------------------------------...E-- S007/00001\n",
      "AGQ--TGIRI----------------------------------...RS- S008/00001\n",
      "ADD--TGFRN----------------------------------...KN- S009/00001\n",
      "KDADGSGVRE----------------------------------...RN- S010/00001\n",
      "AKD--TGMGQ----------------------------------...SV- S011/00001\n",
      "AQD--TGIRV----------------------------------...KT- S012/00001\n",
      "ADT--TGLRW----------------------------------...AP- S013/00001\n",
      "ADD--TSIRV----------------------------------...KN- S014/00001\n",
      "ADD--TGFRI----------------------------------...KG- S015/00001\n",
      "AEA--TGIRV----------------------------------...RP- S016/00001\n",
      "AND--TGIRL----------------------------------...YA- S017/00001\n",
      "ADA--TGIRI----------------------------------...RP- S018/00001\n",
      "...\n",
      "AI-----IRE----------------------------------...E-- S030/00001\n"
     ]
    }
   ],
   "source": [
    "# cwd = os.getcwd()\n",
    "# print(cwd)\n",
    "\n",
    "import os # set the wd\n",
    "\n",
    "from Bio import SeqIO, AlignIO\n",
    "from zoo.wrappers.treebuilders import Phyml\n",
    "from zoo.wrappers.treebuilders import Raxml\n",
    "from zoo.wrappers.treebuilders import Iqtree\n",
    "# regular expression needed to extract species name prior to concatenation\n",
    "import re\n",
    "# for IQtree to print a tree\n",
    "import dendropy\n",
    "\n",
    "\n",
    "\n",
    "# start with ALF output\n",
    "alf_msa_dir = 'results/222dc49d-452f-43bf-a968-90e4fa814b6e/MSA/'\n",
    "\n",
    "file = \"MSA_1_aa.fa\"\n",
    "\n",
    "# eventually will loop through all sim outputs\n",
    "\n",
    "msa = AlignIO.read(alf_msa_dir+\"/\"+file,format=\"fasta\") \n",
    "\n",
    "\n",
    "print(msa)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition the MSA from ALF\n",
    "\n",
    "This is then fed into IQtree (don't think it will work for RaxML or Phyml)\n",
    "\n",
    "Use a script from David to convert fasta format from ALF output to Phylip (relaxed) format for PartitionFinder2 input:\n",
    "\n",
    "ACTUALLY, don't need to do this, at the bottom of the MSA directory for ALF output, it has one file with all alignments together in Phylip format. Otherwise if needed, David's script below does work, but throws an error when that .phy file is in the MSA directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob, os\n",
    "# from Bio import AlignIO\n",
    "\n",
    "# input_folder = '/Users/kgilbert/Documents/UNIL/PartitioningMethods_SimulationProject/results/222dc49d-452f-43bf-a968-90e4fa814b6e/MSA/'\n",
    "\n",
    "# for f in glob.glob(os.path.join(input_folder, '*.fa')):\n",
    "#     input_handle = open(f, \"r\")\n",
    "#     output_handle = open(f.replace('fa','phy'), \"w\")\n",
    "\n",
    "#     align = AlignIO.read(input_handle, \"fasta\")\n",
    "#     AlignIO.write(align, output_handle, \"phylip-relaxed\")\n",
    "\n",
    "#     output_handle.close()\n",
    "#     input_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the cfg file and the input phylip file in the same folder...\n",
    "Will need to iterate the input files that are listed in the first line of teh cfg file (cfg file is the parameter file for partitionfinder2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda2/envs/test\n",
      "\n",
      "  added / updated specs:\n",
      "    - python\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  ca-certificates    pkgs/main/osx-64::ca-certificates-2019.10.16-0\n",
      "  certifi            pkgs/main/osx-64::certifi-2019.9.11-py37_0\n",
      "  libcxx             pkgs/main/osx-64::libcxx-4.0.1-hcfea43d_1\n",
      "  libcxxabi          pkgs/main/osx-64::libcxxabi-4.0.1-hcfea43d_1\n",
      "  libedit            pkgs/main/osx-64::libedit-3.1.20181209-hb402a30_0\n",
      "  libffi             pkgs/main/osx-64::libffi-3.2.1-h475c297_4\n",
      "  ncurses            pkgs/main/osx-64::ncurses-6.1-h0a44026_1\n",
      "  openssl            pkgs/main/osx-64::openssl-1.1.1d-h1de35cc_3\n",
      "  pip                pkgs/main/osx-64::pip-19.3.1-py37_0\n",
      "  python             pkgs/main/osx-64::python-3.7.4-h359304d_1\n",
      "  readline           pkgs/main/osx-64::readline-7.0-h1de35cc_5\n",
      "  setuptools         pkgs/main/osx-64::setuptools-41.4.0-py37_0\n",
      "  sqlite             pkgs/main/osx-64::sqlite-3.30.0-ha441bb4_0\n",
      "  tk                 pkgs/main/osx-64::tk-8.6.8-ha441bb4_0\n",
      "  wheel              pkgs/main/osx-64::wheel-0.33.6-py37_0\n",
      "  xz                 pkgs/main/osx-64::xz-5.2.4-h1de35cc_4\n",
      "  zlib               pkgs/main/osx-64::zlib-1.2.11-h1de35cc_3\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate test\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cannot run partitionfinder2 from here in jupyter. it uses python 2.7.10 or higher BUT not python 3.x\n",
    "# was not able to install pytables dependency of partitionfinder2 with pip, \n",
    "#     had to resort to installing anaconda (v2.7)\n",
    "# also could not manually instal pytables from github because latest version is too far ahead\n",
    "#     to work with python2.7.10\n",
    "# so for now, partitionfinder2 does work when run in the command line within the folder:\n",
    "#       ~/Documents/UNIL//partition_finder_2/\n",
    "# with the command:\n",
    "#        python partitionfinder-2.1.1/PartitionFinderProtein.py partitionfinder-2.1.1/examples/aminoacid/\n",
    "# sometimes the above command doesn't work, but then try again with a new terminal, \n",
    "#    or make a temporary anaconda environment as below, which can be deleted in /opt/anaconda2/envs/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## BELOW DOES NOT SEEM TO SOLVE THE ISSUE when trying to run partitionfinder2 in jupyter\n",
    "\n",
    "#%%bash\n",
    "\n",
    "#cd ../partition_finder_2/partitionfinder-2.1.1/\n",
    "\n",
    "#/opt/anaconda2/bin/conda create -n test python\n",
    "\n",
    "#/opt/anaconda2/bin/conda activate test\n",
    "\n",
    "#python PartitionFinderProtein.py examples/aminoacid/\n",
    "\n",
    "#/opt/anaconda2/bin/conda deactivate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the alignment, build the tree with PhyML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/bin/python3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/kgilbert/Documents/UNIL/PartitioningMethods_SimulationProject',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python37.zip',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages',\n",
       " '/Users/kgilbert/Documents/UNIL/zoo',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/kgilbert/.ipython']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/bin/jupyter\r\n"
     ]
    }
   ],
   "source": [
    "!which jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PATH issues all fixed now, updated bash+profile and restarted jupyter\n",
    "\n",
    "#!echo $PATH\n",
    "\n",
    "#cwd = os.getcwd()\n",
    "#print(cwd)\n",
    "\n",
    "\n",
    "#!export PATH=$PATH:/Users/kgilbert/Documents/UNIL/phyml/src/\n",
    "    \n",
    "#!echo $PATH\n",
    "\n",
    "#sys.path.append('/Users/kgilbert/Documents/UNIL/phyml/src/')\n",
    "\n",
    "#!echo $PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree = Phyml(msa, datatype=\"PROTEIN\")#, binary='/Users/kgilbert/Documents/UNIL/phyml/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "phy_res = tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/------------------------------------------------------------------- S004/00001\n",
      "|                                                                              \n",
      "|                                                            /------ S024/00001\n",
      "|------------------------------------------------------------+                 \n",
      "|                                                            \\------ S021/00001\n",
      "|                                                                              \n",
      "|                                       /--------------------------- S019/00001\n",
      "|                                       |                                      \n",
      "|            /--------------------------+      /-------------------- S023/00001\n",
      "|            |                          |      |                               \n",
      "|            |                          \\------+             /------ S027/00001\n",
      "|            |                                 |      /------+                 \n",
      "|            |                                 |      |      \\------ S001/00001\n",
      "|            |                                 \\------+                        \n",
      "|            |                                        |      /------ S025/00001\n",
      "|            |                                        \\------+                 \n",
      "|            |                                               \\------ S026/00001\n",
      "|     /------+                                                                 \n",
      "+     |      |                                               /------ S003/00001\n",
      "|     |      |      /----------------------------------------+                 \n",
      "|     |      |      |                                        \\------ S022/00001\n",
      "|     |      |      |                                                          \n",
      "|     |      |      |                                        /------ S016/00001\n",
      "|     |      |      |                          /-------------+                 \n",
      "|     |      |      |                          |             \\------ S008/00001\n",
      "|     |      |      |                          |                               \n",
      "|     |      \\------+      /-------------------+             /------ S013/00001\n",
      "|     |             |      |                   |      /------+                 \n",
      "|     |             |      |                   |      |      \\------ S010/00001\n",
      "|     |             |      |                   \\------+                        \n",
      "|     |             |      |                          |      /------ S018/00001\n",
      "|     |             |      |                          \\------+                 \n",
      "|     |             |      |                                 \\------ S006/00001\n",
      "|     |             \\------+                                                   \n",
      "|     |                    |                                 /------ S030/00001\n",
      "|     |                    |                          /------+                 \n",
      "|     |                    |                          |      \\------ S007/00001\n",
      "\\-----+                    |      /-------------------+                        \n",
      "      |                    |      |                   |      /------ S028/00001\n",
      "      |                    |      |                   \\------+                 \n",
      "      |                    |      |                          \\------ S029/00001\n",
      "      |                    \\------+                                            \n",
      "      |                           |     /--------------------------- S005/00001\n",
      "      |                           |     |                                      \n",
      "      |                           |     |             /------------- S015/00001\n",
      "      |                           \\-----+      /------+                        \n",
      "      |                                 |      |      |      /------ S020/00001\n",
      "      |                                 |      |      \\------+                 \n",
      "      |                                 \\------+             \\------ S009/00001\n",
      "      |                                        |                               \n",
      "      |                                        |      /------------- S012/00001\n",
      "      |                                        \\------+                        \n",
      "      |                                               |      /------ S014/00001\n",
      "      |                                               \\------+                 \n",
      "      |                                                      \\------ S017/00001\n",
      "      |                                                                        \n",
      "      |                                                      /------ S002/00001\n",
      "      \\------------------------------------------------------+                 \n",
      "                                                             \\------ S011/00001\n",
      "                                                                               \n",
      "                                                                               \n"
     ]
    }
   ],
   "source": [
    "phy_res.print_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the alignment, build the tree with RAxML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raxmltree = Raxml(msa, datatype=\"PROTEIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No match found for \"alpha:\" (at char 0), (line:1, col:1)\n"
     ]
    }
   ],
   "source": [
    "rax_res = raxmltree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              /----- S025/00001\n",
      "     /--------------------------------------------------------+                \n",
      "     |                                                        \\----- S026/00001\n",
      "     |                                                                         \n",
      "     |     /-------------------------------------------------------- S023/00001\n",
      "     |     |                                                                   \n",
      "     |     |                                            /----------- S004/00001\n",
      "     |     |                                       /----+                      \n",
      "     |     |                                       |    |     /----- S021/00001\n",
      "     |     |                                       |    \\-----+                \n",
      "     |     |          /----------------------------+          \\----- S024/00001\n",
      "/----+     |          |                            |                           \n",
      "|    |     |          |                            |          /----- S002/00001\n",
      "|    |     |          |                            \\----------+                \n",
      "|    |     |          |                                       \\----- S011/00001\n",
      "|    |     |          |                                                        \n",
      "|    |     |          |                            /---------------- S029/00001\n",
      "|    |     |          |                /-----------+                           \n",
      "|    |     |          |                |           |    /----------- S028/00001\n",
      "|    |     |          |                |           \\----+                      \n",
      "|    |     |          |                |                |     /----- S007/00001\n",
      "|    \\-----+          |                |                \\-----+                \n",
      "|          |          |           /----+                      \\----- S030/00001\n",
      "|          |          |           |    |                                       \n",
      "|          |          |           |    |     /---------------------- S005/00001\n",
      "|          |     /----+           |    |     |                                 \n",
      "|          |     |    |           |    |     |                /----- S020/00001\n",
      "|          |     |    |           |    \\-----+          /-----+                \n",
      "|          |     |    |           |          |     /----+     \\----- S009/00001\n",
      "|          |     |    |           |          |     |    |                      \n",
      "|          |     |    |           |          \\-----+    \\----------- S015/00001\n",
      "|          |     |    |           |                |                           \n",
      "|          |     |    |     /-----+                |    /----------- S012/00001\n",
      "|          |     |    |     |     |                \\----+                      \n",
      "+          |     |    |     |     |                     |     /----- S014/00001\n",
      "|          |     |    |     |     |                     \\-----+                \n",
      "|          |     |    |     |     |                           \\----- S017/00001\n",
      "|          |     |    |     |     |                                            \n",
      "|          |     |    |     |     |                           /----- S008/00001\n",
      "|          \\-----+    |     |     |                /----------+                \n",
      "|                |    |     |     |                |          \\----- S016/00001\n",
      "|                |    \\-----+     |                |                           \n",
      "|                |          |     \\----------------+          /----- S010/00001\n",
      "|                |          |                      |    /-----+                \n",
      "|                |          |                      |    |     \\----- S013/00001\n",
      "|                |          |                      \\----+                      \n",
      "|                |          |                           |     /----- S006/00001\n",
      "|                |          |                           \\-----+                \n",
      "|                |          |                                 \\----- S018/00001\n",
      "|                |          |                                                  \n",
      "|                |          |                                 /----- S022/00001\n",
      "|                |          \\---------------------------------+                \n",
      "|                |                                            \\----- S003/00001\n",
      "|                |                                                             \n",
      "|                \\-------------------------------------------------- S019/00001\n",
      "|                                                                              \n",
      "|------------------------------------------------------------------- S027/00001\n",
      "|                                                                              \n",
      "\\------------------------------------------------------------------- S001/00001\n",
      "                                                                               \n",
      "                                                                               \n"
     ]
    }
   ],
   "source": [
    "#rax_res.values()\n",
    "\n",
    "rax_res['tree'].print_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the alignment, build the tree with IQTree\n",
    "\n",
    "For input to IQtree, must have a partition file in RAxML or NEXUS format\n",
    "for NEXUS, each partition could come from a separate alignment file; this is not possible for RAxML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqtree = Iqtree(msa, datatype=\"PROTEIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_res = iqtree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/------------------------------------------------------------------- S001 00001\n",
      "|                                                                              \n",
      "|                                                             /----- S002 00001\n",
      "|                                                  /----------+                \n",
      "|                                                  |          \\----- S011 00001\n",
      "|                     /----------------------------+                           \n",
      "|                     |                            |    /----------- S004 00001\n",
      "|                     |                            \\----+                      \n",
      "|                     |                                 |     /----- S021 00001\n",
      "|                     |                                 \\-----+                \n",
      "|                     |                                       \\----- S024 00001\n",
      "|                     |                                                        \n",
      "|                     |                                       /----- S003 00001\n",
      "|                     |     /---------------------------------+                \n",
      "|                /----+     |                                 \\----- S022 00001\n",
      "|                |    |     |                                                  \n",
      "|                |    |     |                /---------------------- S005 00001\n",
      "|                |    |     |                |                                 \n",
      "|                |    |     |                |                /----- S009 00001\n",
      "|                |    |     |          /-----+          /-----+                \n",
      "|                |    |     |          |     |     /----+     \\----- S020 00001\n",
      "|                |    |     |          |     |     |    |                      \n",
      "|                |    |     |          |     \\-----+    \\----------- S015 00001\n",
      "|                |    |     |          |           |                           \n",
      "|                |    \\-----+          |           |    /----------- S012 00001\n",
      "|                |          |          |           \\----+                      \n",
      "|                |          |     /----+                |     /----- S014 00001\n",
      "|                |          |     |    |                \\-----+                \n",
      "|                |          |     |    |                      \\----- S017 00001\n",
      "+                |          |     |    |                                       \n",
      "|                |          |     |    |                      /----- S007 00001\n",
      "|                |          |     |    |                /-----+                \n",
      "|          /-----+          |     |    |                |     \\----- S030 00001\n",
      "|          |     |          |     |    \\----------------+                      \n",
      "|          |     |          |     |                     |     /----- S028 00001\n",
      "|          |     |          \\-----+                     \\-----+                \n",
      "|          |     |                |                           \\----- S029 00001\n",
      "|          |     |                |                                            \n",
      "|          |     |                |                           /----- S006 00001\n",
      "|          |     |                |                     /-----+                \n",
      "|          |     |                |                     |     \\----- S018 00001\n",
      "|          |     |                |                /----+                      \n",
      "|    /-----+     |                |                |    |     /----- S010 00001\n",
      "|    |     |     |                |                |    \\-----+                \n",
      "|    |     |     |                \\----------------+          \\----- S013 00001\n",
      "|    |     |     |                                 |                           \n",
      "|    |     |     |                                 |          /----- S008 00001\n",
      "|    |     |     |                                 \\----------+                \n",
      "|----+     |     |                                            \\----- S016 00001\n",
      "|    |     |     |                                                             \n",
      "|    |     |     \\-------------------------------------------------- S019 00001\n",
      "|    |     |                                                                   \n",
      "|    |     \\-------------------------------------------------------- S023 00001\n",
      "|    |                                                                         \n",
      "|    |                                                        /----- S025 00001\n",
      "|    \\--------------------------------------------------------+                \n",
      "|                                                             \\----- S026 00001\n",
      "|                                                                              \n",
      "\\------------------------------------------------------------------- S027 00001\n",
      "                                                                               \n",
      "                                                                               \n"
     ]
    }
   ],
   "source": [
    "# old way before Adrian updated the wrapper:\n",
    "# iqtree_res = dendropy.Tree.get(data=iq_res, schema='newick')\n",
    "iq_res['tree'].print_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now I can build all the trees, next need to use partitioning methods to see if/when we get better/worse trees depending on the AIC/BIC values\n",
    "\n",
    "Lanfear et al 2008, MBE has PartitionFinder (v1 and v2)\n",
    "\n",
    "You have to a priori define the number of data blocks? Which then creates the potential number of partitioning schemes..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IQTree uses partition methods during its tree building (different above?) so that would combine steps 2 and 3\n",
    "still have to define where the partitions are a priori\n",
    "3 types of partition models:\n",
    "* edge-equal -- branch lengths same across all branches\n",
    "* edge-proportional -- each partition has its own specific rate that rescales all of its branch lengths, i.e. diff. evolutionary rates between partitions\n",
    "* edge-unlinked -- most parameter-rich model, each partition has its own set of branch lengths\n",
    "they recommend edge-proportional, saying the 3rd might overfit and the 1st does not allow variation in speeds btwn partitions (so what does it allow????)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOT USING ANY Of THIS CURRENTLY\n",
    "\n",
    "\n",
    "#unalign_msa_dir = 'unaligned_MSA/'\n",
    "# right now, 200 .fa files\n",
    "#  infile = r\"MSA_1_aa.fa\"\n",
    "#  outfile = r\"unaligned_MSA_1_aa.fa\"# un-align them (remove the \"-\" from all locations in all files)\n",
    "\n",
    "# one way of doing it with a loop\n",
    "#for i in range(1,5):  # change to 201 to do all 200 files\n",
    "#    infile = \"%sMSA_%d_aa.fa\" % (alf_msa_dir, i)\n",
    "#    #print(infile)\n",
    "#    outfile = r\"%sunaligned_MSA_%d_aa.fa\" % (unalign_msa_dir, i)\n",
    "#    \n",
    "#    fin = open(infile,\"r\")\n",
    "#    fout = open(outfile,\"w+\")\n",
    "#    for line in fin:\n",
    "#        line = line.replace(\"-\", \"\")\n",
    "#        fout.write(line)\n",
    "#    fin.close()\n",
    "#    fout.close()\n",
    "#    print(i)\n",
    "\n",
    "# fancier way of doing it, ala Christophe's code in treebuilding tutorial\n",
    "# for file in os.listdir(alf_msa_dir):\n",
    "#     if file.endswith(\".fa\"):\n",
    "#         print(file)\n",
    "#         infile = AlignIO.read(alf_msa_dir+'/'+file, \"fasta\")\n",
    "#         outfile = unalign_msa_dir+'/'+file\n",
    "#      \n",
    "#         fin = open(infile,\"r\") ## THIS PART DOESN'T WORK, bc it is already in MSA format?\n",
    "#         fout = open(outfile,\"w+\")\n",
    "#         for line in fin:\n",
    "#             line = line.replace(\"-\", \"\")\n",
    "#             fout.write(line)\n",
    "#         fin.close()\n",
    "#         fout.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the inferred trees match the true tree?\n",
    "### How to assess whether the trees are better recovered or not with partitioning/better AIC/BIC\n",
    "\n",
    "- monophyly score - a measure of how well a phylogenetic tree recoveres monophyletic lineages\n",
    "- Robinson Foulds distance - captures the variance in the best tree generated; looks at what inner groups are kept in some paritions?\n",
    "\n",
    "Provide the Newick tree, and Jeremy had scripts that then calculate the two above measures. Needs a clade(???) file? I think this is just a list of all the samples, which for me would be the number of simulated species. Plus the Newick tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeremy - Robinson-Foulds script\n",
    "\"\"\"\n",
    "Calculates RF distances between two trees\n",
    "\"\"\"\n",
    "\n",
    "from ete3 import Tree\n",
    "\n",
    "def collapse_branches(TREE_FILE,SUPPORT_THRESHOLD):\n",
    "    t = Tree(TREE_FILE)\n",
    "    for node in t.get_descendants():\n",
    "        if not node.is_leaf() and (node.support <= SUPPORT_THRESHOLD):\n",
    "            node.delete()\n",
    "    return t\n",
    "\n",
    "\n",
    "def count_internal(tree):\n",
    "    tree.unroot()\n",
    "    edges=-1\n",
    "    for edge in tree.traverse():\n",
    "        if not edge.is_leaf():\n",
    "            edges+=1\n",
    "    return edges\n",
    "\n",
    "def rf_distance(tree1,tree2,option=False):\n",
    "#    if option=='collapse':\n",
    "#        t1 = collapse_branches(tree1,0.75)\n",
    "#        t2 = collapse_branches(tree2,0.75)\n",
    "#        option = 'reduced'\n",
    "#    else:\n",
    "#        t1 = Tree(tree1)\n",
    "#        t2 = Tree(tree2)\n",
    "\n",
    "    t1.unroot()\n",
    "    t2.unroot()\n",
    "\n",
    "    rf = t1.robinson_foulds(t2,unrooted_trees=True)\n",
    "\n",
    "    rf_dist = rf[0]\n",
    "    max_rf = rf[1]\n",
    "    num_leaves=len(rf[2])\n",
    "\n",
    "    max_resolved_score = (2*num_leaves)-6\n",
    "\n",
    "    internal_branches_t1 = count_internal(t1)\n",
    "    internal_branches_t2 = count_internal(t2)\n",
    "\n",
    "    total_internal = internal_branches_t1 + internal_branches_t2\n",
    "\n",
    "    num_missing_splits_t1 = num_leaves - 3 - internal_branches_t1\n",
    "    num_missing_splits_t2 = num_leaves - 3 - internal_branches_t2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    rf_dist_upper = rf_dist + num_missing_splits_t1 + num_missing_splits_t2\n",
    "\n",
    "\n",
    "    #If normalise by (num intenral branches)\n",
    "    if option=='reduced':\n",
    "        normalised_rf = rf_dist/total_internal\n",
    "\n",
    "    elif option=='upper':\n",
    "    #If add score to create upper bound due to being polytomy\n",
    "        normalised_rf = rf_dist_upper/max_resolved_score\n",
    "    else:\n",
    "        normalised_rf = rf_dist/max_resolved_score\n",
    "\n",
    "    return normalised_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compare these two trees\n",
    "# later on --- use the actual tree from ALF sims...\n",
    "\n",
    "#print(phy_res)\n",
    "\n",
    "#print('\\n')\n",
    "\n",
    "#print(iqtree_res)\n",
    "\n",
    "#print(rax_res['tree'])\n",
    "\n",
    "## NEED TO APPEND A ';' TO THE TREE STRINGS, CAN'T SEEM TO DO THIS TO THE TREE FORMAT within python?\n",
    "# write each tree to a file and then read from there for RF calcs\n",
    "\n",
    "with open('iqtree.nw', 'w') as f:\n",
    "    print(iq_res['tree'], \";\", file=f)\n",
    "\n",
    "with open('phyml.nw', 'w') as f:\n",
    "    print(phy_res, \";\", file=f)\n",
    "\n",
    "with open('raxml.nw', 'w') as f:\n",
    "    print(rax_res['tree'], \";\", file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = Tree (\"results/222dc49d-452f-43bf-a968-90e4fa814b6e/RealTree.nwk\")\n",
    "\n",
    "t1 = Tree(\"iqtree.nw\")\n",
    "t2 = Tree(\"phyml.nw\")\n",
    "t3 = Tree(\"raxml.nw\")\n",
    "\n",
    "t4=Tree(\"test_out.txt\")\n",
    "\n",
    "#print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the RF script to my trees; compare original simulated tree to each inferred tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_distance(t0, t1) # vs iqtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_distance(t0, t2) # vs phyml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_distance(t0, t3) # vs raxml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TestingPartitioningMethods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
