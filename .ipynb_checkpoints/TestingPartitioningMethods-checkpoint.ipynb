{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating potential overfitting in partitioning methods for phylogenetic inference\n",
    "\n",
    "Even if information criteria like AIC, AICc, or BIC show better models with more partitions, the trees do not seem to be improving. Is this some sort of overfitting/overparameterizing?\n",
    "\n",
    "Aim is to test this using simulated trees\n",
    "\n",
    "\n",
    "From Jeremy's paper, the pipeline was:\n",
    "\n",
    "Each concatenated alignment was partitioned using PartitionFinder v2 (Lanfear et al. 2017) and MtPAN(3) (Nardi et al. 2014) using the Gap_script_charset.pl, Gap_script_physio.pl, and Gap_script.R scripts (Nardi et al. 2014). Moreover, the dataset was partitioned by its original OGs. For MtPAN, we used k=10 clusters, using 10,000 k-means seeds and 250 simulations. The initial data blocks fed to PartitionFinder were the genes of each of the datasets. We used a relaxed clustering search approach (Lanfear et al. 2014), the linked branch lengths option, and all protein models of evolution were considered, with BIC model selection.\n",
    "\n",
    "Partitioning schemes were inferred using RAxML and IQ-TREE. In RAxML (Stamatakis 2014), the tree search comprises of two main phases. During the first phase, the best candidate trees in terms of likelihood scores are re-evaluated, with the 20 best scoring trees saved. Beginning with an initial parsimony tree, the algorithm performs cycles of Subtree Pruning and Regrafting (SPR) moves, followed by branch length optimisations of the 20 best trees found during the SPRs. Here, each SPR cycle performs an SPR move on each of the subtrees and reinserts subtrees between a pre-determined rearrangement radius. If an improvement in likelihood is found, the tree is retained immediately. A more thorough rearrangement algorithm is then performed in order to find more likelihood improvements on the 20 best trees, in which branch lengths are optimised. In the second phase, candidate trees are evaluated more thoroughly, by altering the SPR radius. First, a smaller radius is used to apply SPRs, with the 20 best trees saved. If none of these 20 trees improve the tree, the radius in which SPRs are performed is extended, and so forth. IQ-TREE (Nguyen et al. 2015) uses a stochastic algorithm in order to find ML trees. It begins by generating 100 parsimony trees. From these, the 20 trees with the best ML score, and each with a unique topology, are selected. A stochastic hill climbing Nearest Neighbor Interchanges (NNI) algorithm is then used to find the best ML scoring trees. These trees are then further optimised in order to find the highest likelihood tree.\n",
    "\n",
    "RAxML_Default trees were inferred using automatic model selection and a gamma model for rate heterogeneity, using the PROTGAMMAAUTO flag. The BIC criterion was used for model selection. Rapid bootstrap was implemented, with 100 replicates.\n",
    "\n",
    "Similarly, for IQTREE_Default, the default settings, which implements ModelFinder (Kalyaanamoorthy et al. 2017) was implemented with a gamma model for rate heterogeneity. Ultrafast bootstraps was also implemented, with 1000 replicates (Hoang et al. 2018). Additionally, we inferred trees using ModelFinder without the constraint of a gamma model (IQTREE_FREERATE). These trees are included in the Supplementary materials.\n",
    "\n",
    "For RAxML_Partition, IQTREE_Partition, RAxML_MtPAN and IQTREE_MtPAN, the ModelFinder implementation in IQTREE was used in order to find the most suitable model for each partition. For the IQTREE methods, all possible models of evolution were included, including mixture models. For the RAxML implementations, only models found in RAxML were included for selection (i.e., mixture models were not included). A gamma rate of heterogeneity was selected, as well as linked branch length models.\n",
    "\n",
    "For both RAxML_PartitionFinder and IQTREE_PartitionFinder, a gamma rate of heterogeneity was used with the best scheme found by PartitionFinder. We also used edge-linked branch lengths when constructing phylogenetic trees. In the case of RAxML_PartitionFinder, 100 rapid bootstrap replicates were found. For IQTREE_PartitionFinder, 1000 ultrafast bootstrap replicates were inferred.\n",
    "\n",
    "In addition to partitioning models, we also assess the performance of a protein mixture model. We used the GHOST model implemented in IQ-TREE, an edge unlinked mixture model designed to deal with heterotachy.\n",
    "\n",
    "For our partitioned analysis, we used edge linked branch lengths. Edge unlinked branch lengths have 2n-3 extra parameters per additional partition (where n is the number of taxa), rather than a single extra parameter. Therefore, it is likely that edge unlinked models are over parameterised. The edge unlinked model was chosen for the IQTREE_GHOST method because it was used for its potential to account for heterotachy, which the edge unlinked model accounts for. For better comparison with the other methods in this study, the method should also be evaluated using the edge linked model.\n",
    "\n",
    "\n",
    "#### First, simulate (a range of?) trees with ALF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "alfsim inputfile\n",
    "\n",
    "# or can do bash this way:\n",
    "!alfsim inputfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From ALF MSA output, either partition or not, and then build the tree to compare to the known simulated tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingleLetterAlphabet() alignment with 30 rows and 398 columns\n",
      "AEE--TVLAV----------------------------------...KE- S001/00001\n",
      "AKQ--TVIGL----------------------------------...SF- S002/00001\n",
      "AQL--TGIDT----------------------------------...SW- S003/00001\n",
      "ADD--TGIGS----------------------------------...RA- S004/00001\n",
      "ASD--DGIRI----------------------------------...DI- S005/00001\n",
      "AKS--TGIRP----------------------------------...RP- S006/00001\n",
      "AV-----IRQ----------------------------------...E-- S007/00001\n",
      "AGQ--TGIRI----------------------------------...RS- S008/00001\n",
      "ADD--TGFRN----------------------------------...KN- S009/00001\n",
      "KDADGSGVRE----------------------------------...RN- S010/00001\n",
      "AKD--TGMGQ----------------------------------...SV- S011/00001\n",
      "AQD--TGIRV----------------------------------...KT- S012/00001\n",
      "ADT--TGLRW----------------------------------...AP- S013/00001\n",
      "ADD--TSIRV----------------------------------...KN- S014/00001\n",
      "ADD--TGFRI----------------------------------...KG- S015/00001\n",
      "AEA--TGIRV----------------------------------...RP- S016/00001\n",
      "AND--TGIRL----------------------------------...YA- S017/00001\n",
      "ADA--TGIRI----------------------------------...RP- S018/00001\n",
      "...\n",
      "AI-----IRE----------------------------------...E-- S030/00001\n"
     ]
    }
   ],
   "source": [
    "# cwd = os.getcwd()\n",
    "# print(cwd)\n",
    "\n",
    "import os # set the wd\n",
    "\n",
    "from Bio import SeqIO, AlignIO\n",
    "from zoo.wrappers.treebuilders import Phyml\n",
    "from zoo.wrappers.treebuilders import Raxml\n",
    "from zoo.wrappers.treebuilders import Iqtree\n",
    "# regular expression needed to extract species name prior to concatenation\n",
    "import re\n",
    "# for IQtree to print a tree\n",
    "import dendropy\n",
    "\n",
    "\n",
    "\n",
    "# start with ALF output\n",
    "alf_msa_dir = 'results/222dc49d-452f-43bf-a968-90e4fa814b6e/MSA/'\n",
    "\n",
    "file = \"MSA_1_aa.fa\"\n",
    "\n",
    "# eventually will loop through all sim outputs\n",
    "\n",
    "msa = AlignIO.read(alf_msa_dir+\"/\"+file,format=\"fasta\") \n",
    "\n",
    "\n",
    "print(msa)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition the MSA from ALF\n",
    "\n",
    "This is then fed into IQtree (don't think it will work for Phyml, but should also be possible with RaxML)\n",
    "\n",
    "Use a script from David to convert fasta format from ALF output to Phylip (relaxed) format for PartitionFinder2 input:\n",
    "\n",
    "ACTUALLY, don't need to do this, at the bottom of the MSA directory for ALF output, it has one file with all alignments together in Phylip format. Otherwise if needed, David's script below does work, but throws an error when that .phy file is in the MSA directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob, os\n",
    "# from Bio import AlignIO\n",
    "\n",
    "# input_folder = '/Users/kgilbert/Documents/UNIL/PartitioningMethods_SimulationProject/results/222dc49d-452f-43bf-a968-90e4fa814b6e/MSA/'\n",
    "\n",
    "# for f in glob.glob(os.path.join(input_folder, '*.fa')):\n",
    "#     input_handle = open(f, \"r\")\n",
    "#     output_handle = open(f.replace('fa','phy'), \"w\")\n",
    "\n",
    "#     align = AlignIO.read(input_handle, \"fasta\")\n",
    "#     AlignIO.write(align, output_handle, \"phylip-relaxed\")\n",
    "\n",
    "#     output_handle.close()\n",
    "#     input_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the cfg file and the input phylip file in the same folder...\n",
    "Will need to iterate the input files that are listed in the first line of the cfg file (cfg file is the parameter file for partitionfinder2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot run partitionfinder2 from here in jupyter. it uses python 2.7.10 or higher BUT not python 3.x\n",
    "# was not able to install pytables dependency of partitionfinder2 with pip, \n",
    "#     had to resort to installing anaconda (v2.7)\n",
    "# also could not manually instal pytables from github because latest version is too far ahead\n",
    "#     to work with python2.7.10\n",
    "#     e.g. this fails:  pip install --install-option='--prefix=<PREFIX>' \\\n",
    "#-e git+https://github.com/PyTables/PyTables.git@v.3.1#egg=tables\n",
    "# so for now, partitionfinder2 does work when run in the command line within the folder:\n",
    "#       ~/Documents/UNIL//partition_finder_2/\n",
    "# with the command:\n",
    "#        python partitionfinder-2.1.1/PartitionFinderProtein.py partitionfinder-2.1.1/examples/aminoacid/\n",
    "# sometimes the above command doesn't work, but then try again with a new terminal, \n",
    "#    or make a temporary anaconda environment as below, which can be deleted in /opt/anaconda2/envs/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## BELOW DOES NOT SEEM TO SOLVE THE ISSUE when trying to run partitionfinder2 in jupyter\n",
    "\n",
    "#%%bash\n",
    "\n",
    "#cd ../partition_finder_2/partitionfinder-2.1.1/\n",
    "\n",
    "#/opt/anaconda2/bin/conda create -n test python\n",
    "\n",
    "#/opt/anaconda2/bin/conda activate test\n",
    "\n",
    "#python PartitionFinderProtein.py examples/aminoacid/\n",
    "\n",
    "#/opt/anaconda2/bin/conda deactivate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran some prelim tests in the terminal. .cfg file data_blocks specification is still a bit confusing. What types of partitions should I specify a priori for an amino acid model? If I only do one gene (gene = 0-398) the program throws traceback errors. But if I specify at least 2 genes, e.g. 1-300 and 301-398, it works and creates output.\n",
    "See test1 and test2 folders in PartitionAlfSims/.\n",
    "\n",
    "Also, manually cut the first section of the replicate sims concatenated into that one large Phylip file, so will need to write a script to parse these out for large-scale analyses. \n",
    "\n",
    "Also will want to vary the options to do AIC, AICc, and BIC results options (specified in .cfg).\n",
    "\n",
    "Anyway, from that output, test running raxml and iqtree with partition files. The best-fit partition file is written in nexus format within the larger output text file called \"best_scheme.txt\", where it gives both the IQtree format and Raxml format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQ-TREE multicore version 1.6.12 for Mac OS X 64-bit built Aug 15 2019\n",
      "Developed by Bui Quang Minh, Nguyen Lam Tung, Olga Chernomor,\n",
      "Heiko Schmidt, Dominik Schrempf, Michael Woodhams.\n",
      "\n",
      "Host:    staff-202-197.eduroam.unibe.ch (AVX2, FMA3, 16 GB RAM)\n",
      "Command: iqtree -s ../partition_finder_2/PartitionAlfSims/test1_24oct/test_MSA1.phy -spp ../partition_finder_2/PartitionAlfSims/test1_partitionFile.nex -redo\n",
      "Seed:    60671 (Using SPRNG - Scalable Parallel Random Number Generator)\n",
      "Time:    Thu Oct 24 17:08:05 2019\n",
      "Kernel:  AVX+FMA - 1 threads (4 CPU cores detected)\n",
      "\n",
      "HINT: Use -nt option to specify number of threads because your CPU has 4 cores!\n",
      "HINT: -nt AUTO will automatically determine the best number of threads to use.\n",
      "\n",
      "Reading partition model file ../partition_finder_2/PartitionAlfSims/test1_partitionFile.nex ...\n",
      "Reading alignment file ../partition_finder_2/PartitionAlfSims/test1_24oct/test_MSA1.phy ... Phylip format detected\n",
      "Alignment most likely contains protein sequences\n",
      "WARNING: 4 sites contain only gaps or ambiguous characters.\n",
      "Alignment has 30 sequences with 398 columns, 349 distinct patterns\n",
      "189 parsimony-informative, 39 singleton sites, 170 constant sites\n",
      "WARNING: Some sequence names are changed as follows:\n",
      "S001/00001 -> S001_00001\n",
      "S002/00001 -> S002_00001\n",
      "S003/00001 -> S003_00001\n",
      "S004/00001 -> S004_00001\n",
      "S005/00001 -> S005_00001\n",
      "S006/00001 -> S006_00001\n",
      "S007/00001 -> S007_00001\n",
      "S008/00001 -> S008_00001\n",
      "S009/00001 -> S009_00001\n",
      "S010/00001 -> S010_00001\n",
      "S011/00001 -> S011_00001\n",
      "S012/00001 -> S012_00001\n",
      "S013/00001 -> S013_00001\n",
      "S014/00001 -> S014_00001\n",
      "S015/00001 -> S015_00001\n",
      "S016/00001 -> S016_00001\n",
      "S017/00001 -> S017_00001\n",
      "S018/00001 -> S018_00001\n",
      "S019/00001 -> S019_00001\n",
      "S020/00001 -> S020_00001\n",
      "S021/00001 -> S021_00001\n",
      "S022/00001 -> S022_00001\n",
      "S023/00001 -> S023_00001\n",
      "S024/00001 -> S024_00001\n",
      "S025/00001 -> S025_00001\n",
      "S026/00001 -> S026_00001\n",
      "S027/00001 -> S027_00001\n",
      "S028/00001 -> S028_00001\n",
      "S029/00001 -> S029_00001\n",
      "S030/00001 -> S030_00001\n",
      "\n",
      "            Gap/Ambiguity  Composition  p-value\n",
      "   1  S001_00001   43.47%    passed     69.18%\n",
      "   2  S002_00001   45.23%    passed     72.59%\n",
      "   3  S003_00001   44.97%    passed     73.33%\n",
      "   4  S004_00001   41.21%    passed     91.08%\n",
      "   5  S005_00001   43.72%    passed     87.07%\n",
      "   6  S006_00001   45.48%    passed     58.96%\n",
      "   7  S007_00001   49.50%    passed     78.23%\n",
      "   8  S008_00001   44.72%    passed     93.69%\n",
      "   9  S009_00001   46.23%    passed     91.47%\n",
      "  10  S010_00001   44.97%    passed     99.17%\n",
      "  11  S011_00001   44.72%    passed     95.41%\n",
      "  12  S012_00001   45.48%    passed     95.63%\n",
      "  13  S013_00001   40.95%    passed     96.14%\n",
      "  14  S014_00001   45.48%    passed     77.04%\n",
      "  15  S015_00001   45.73%    passed     83.99%\n",
      "  16  S016_00001   45.73%    passed     99.81%\n",
      "  17  S017_00001   45.73%    passed     96.63%\n",
      "  18  S018_00001   45.23%    passed     95.67%\n",
      "  19  S019_00001   43.47%    passed     97.11%\n",
      "  20  S020_00001   46.23%    passed     94.52%\n",
      "  21  S021_00001   43.47%    passed     96.25%\n",
      "  22  S022_00001   44.97%    passed     93.66%\n",
      "  23  S023_00001   43.22%    passed     96.75%\n",
      "  24  S024_00001   43.47%    passed     82.73%\n",
      "  25  S025_00001   33.42%    passed     83.03%\n",
      "  26  S026_00001   43.47%    passed     87.02%\n",
      "  27  S027_00001   43.22%    passed     93.82%\n",
      "  28  S028_00001   48.74%    passed     67.01%\n",
      "  29  S029_00001   49.75%    passed     66.21%\n",
      "  30  S030_00001   49.50%    passed     91.58%\n",
      "****  TOTAL        44.72%  0 sequences failed composition chi2 test (p-value<5%; df=19)\n",
      "\n",
      "Loading 1 partitions...\n",
      "Subset\tType\tSeqs\tSites\tInfor\tInvar\tModel\tName\n",
      "1\tAA\t30\t398\t189\t170\tLG+G\tSubset1\n",
      "Degree of missing data: 0.000\n",
      "Info: multi-threading strategy over partitions\n",
      "\n",
      "\n",
      "Create initial parsimony tree by phylogenetic likelihood library (PLL)... 0.006 seconds\n",
      "\n",
      "NOTE: 6 MB RAM (0 GB) is required!\n",
      "Estimate model parameters (epsilon = 0.100)\n",
      "Initial log-likelihood: -9519.244\n",
      "Current log-likelihood at step 1: -9471.002\n",
      "Current log-likelihood at step 2: -9468.884\n",
      "Current log-likelihood at step 3: -9468.853\n",
      "Partition-specific rates:  1.000\n",
      "Parameters optimization took 2 rounds (0.412 sec)\n",
      "\n",
      "Computing ML distances based on estimated model parameters... 0.260 sec\n",
      "Computing BIONJ tree...\n",
      "0.002 seconds\n",
      "Log-likelihood of BIONJ tree: -9467.233\n",
      "--------------------------------------------------------------------\n",
      "|             INITIALIZING CANDIDATE TREE SET                      |\n",
      "--------------------------------------------------------------------\n",
      "Generating 98 parsimony trees... 0.431 second\n",
      "Computing log-likelihood of 98 initial trees ... 4.135 seconds\n",
      "Current best score: -9467.233\n",
      "\n",
      "Do NNI search on 20 best initial trees\n",
      "Estimate model parameters (epsilon = 0.100)\n",
      "Initial log-likelihood: -9459.080\n",
      "Current log-likelihood at step 1: -9459.078\n",
      "Parameters optimization took 0 rounds (0.089 sec)\n",
      "\n",
      "BETTER TREE FOUND at iteration 1: -9459.078\n",
      "Estimate model parameters (epsilon = 0.100)\n",
      "Initial log-likelihood: -9458.898\n",
      "Current log-likelihood at step 1: -9458.898\n",
      "Parameters optimization took 0 rounds (0.072 sec)\n",
      "\n",
      "BETTER TREE FOUND at iteration 2: -9458.898\n",
      "Iteration 10 / LogL: -9458.898 / Time: 0h:0m:11s\n",
      "Iteration 20 / LogL: -9458.899 / Time: 0h:0m:16s\n",
      "Finish initializing candidate tree set (2)\n",
      "Current best tree score: -9458.898 / CPU time: 15.463\n",
      "Number of iterations: 20\n",
      "--------------------------------------------------------------------\n",
      "|               OPTIMIZING CANDIDATE TREE SET                      |\n",
      "--------------------------------------------------------------------\n",
      "Iteration 30 / LogL: -9458.899 / Time: 0h:0m:23s (0h:0m:58s left)\n",
      "Iteration 40 / LogL: -9458.906 / Time: 0h:0m:29s (0h:0m:46s left)\n",
      "Iteration 50 / LogL: -9458.923 / Time: 0h:0m:36s (0h:0m:38s left)\n",
      "Iteration 60 / LogL: -9459.082 / Time: 0h:0m:44s (0h:0m:31s left)\n",
      "Iteration 70 / LogL: -9458.899 / Time: 0h:0m:51s (0h:0m:23s left)\n",
      "Iteration 80 / LogL: -9459.078 / Time: 0h:0m:58s (0h:0m:16s left)\n",
      "Iteration 90 / LogL: -9458.899 / Time: 0h:1m:6s (0h:0m:9s left)\n",
      "Iteration 100 / LogL: -9459.090 / Time: 0h:1m:13s (0h:0m:1s left)\n",
      "TREE SEARCH COMPLETED AFTER 103 ITERATIONS / Time: 0h:1m:15s\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "|                    FINALIZING TREE SEARCH                        |\n",
      "--------------------------------------------------------------------\n",
      "Performs final model parameters optimization\n",
      "Estimate model parameters (epsilon = 0.010)\n",
      "Initial log-likelihood: -9458.898\n",
      "Current log-likelihood at step 1: -9458.898\n",
      "Partition-specific rates:  1.000\n",
      "Parameters optimization took 0 rounds (0.094 sec)\n",
      "\n",
      "BEST SCORE FOUND : -9458.898\n",
      "Total tree length: 18.655\n",
      "\n",
      "Total number of iterations: 103\n",
      "CPU time used for tree search: 70.204 sec (0h:1m:10s)\n",
      "Wall-clock time used for tree search: 75.074 sec (0h:1m:15s)\n",
      "Total CPU time used: 71.198 sec (0h:1m:11s)\n",
      "Total wall-clock time used: 76.106 sec (0h:1m:16s)\n",
      "\n",
      "Analysis results written to: \n",
      "  IQ-TREE report:                ../partition_finder_2/PartitionAlfSims/test1_partitionFile.nex.iqtree\n",
      "  Maximum-likelihood tree:       ../partition_finder_2/PartitionAlfSims/test1_partitionFile.nex.treefile\n",
      "  Likelihood distances:          ../partition_finder_2/PartitionAlfSims/test1_partitionFile.nex.mldist\n",
      "  Screen log file:               ../partition_finder_2/PartitionAlfSims/test1_partitionFile.nex.log\n",
      "\n",
      "Date and Time: Thu Oct 24 17:09:21 2019\n"
     ]
    }
   ],
   "source": [
    "# Jeremy did: iqtree -s ${CONCAT_ALIGNMENT} -seed 12345 -nt 4 -spp ${PARTITION_FILE} -bb 1000\n",
    "\n",
    "!iqtree -s ../partition_finder_2/PartitionAlfSims/test1_24oct/test_MSA1.phy -spp ../partition_finder_2/PartitionAlfSims/test1_partitionFile.nex -redo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeremy - Robinson-Foulds script\n",
    "\"\"\"\n",
    "Calculates RF distances between two trees\n",
    "\"\"\"\n",
    "\n",
    "from ete3 import Tree\n",
    "\n",
    "def collapse_branches(TREE_FILE,SUPPORT_THRESHOLD):\n",
    "    t = Tree(TREE_FILE)\n",
    "    for node in t.get_descendants():\n",
    "        if not node.is_leaf() and (node.support <= SUPPORT_THRESHOLD):\n",
    "            node.delete()\n",
    "    return t\n",
    "\n",
    "\n",
    "def count_internal(tree):\n",
    "    tree.unroot()\n",
    "    edges=-1\n",
    "    for edge in tree.traverse():\n",
    "        if not edge.is_leaf():\n",
    "            edges+=1\n",
    "    return edges\n",
    "\n",
    "def rf_distance(tree1,tree2,option=False):\n",
    "#    if option=='collapse':\n",
    "#        t1 = collapse_branches(tree1,0.75)\n",
    "#        t2 = collapse_branches(tree2,0.75)\n",
    "#        option = 'reduced'\n",
    "#    else:\n",
    "#        t1 = Tree(tree1)\n",
    "#        t2 = Tree(tree2)\n",
    "\n",
    "    t1.unroot()\n",
    "    t2.unroot()\n",
    "\n",
    "    rf = t1.robinson_foulds(t2,unrooted_trees=True)\n",
    "\n",
    "    rf_dist = rf[0]\n",
    "    max_rf = rf[1]\n",
    "    num_leaves=len(rf[2])\n",
    "\n",
    "    max_resolved_score = (2*num_leaves)-6  # this comes from comparing two trees where each has n-3 internal beanches and n is total number of branches\n",
    "\n",
    "    internal_branches_t1 = count_internal(t1)\n",
    "    internal_branches_t2 = count_internal(t2)\n",
    "\n",
    "    total_internal = internal_branches_t1 + internal_branches_t2\n",
    "\n",
    "    num_missing_splits_t1 = num_leaves - 3 - internal_branches_t1\n",
    "    num_missing_splits_t2 = num_leaves - 3 - internal_branches_t2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    rf_dist_upper = rf_dist + num_missing_splits_t1 + num_missing_splits_t2\n",
    "\n",
    "\n",
    "    #If normalise by (num intenral branches)\n",
    "    if option=='reduced':\n",
    "        normalised_rf = rf_dist/total_internal\n",
    "\n",
    "    elif option=='upper':\n",
    "    #If add score to create upper bound due to being polytomy\n",
    "        normalised_rf = rf_dist_upper/max_resolved_score\n",
    "    else:\n",
    "        normalised_rf = rf_dist/max_resolved_score\n",
    "\n",
    "    return normalised_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take that output newick tree and read in below to compare to simulated tree\n",
    "\n",
    "t0 = Tree (\"results/222dc49d-452f-43bf-a968-90e4fa814b6e/RealTree.nwk\")\n",
    "\n",
    "partition_iqtree = Tree(\"../partition_finder_2/PartitionAlfSims/test1_partitionFile.nex.treefile\")\n",
    "\n",
    "rf_distance(t0, partition_iqtree) # vs iqtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for partitioning with raxml, Jeremy did:\n",
    "# raxmlHPC-PTHREADS -T 4 -f a -m PROTGAMMAWAG -s ${CONCAT_ALIGNMENT} -p 15826 -x 15826 -q ${PARTITION_FILE} -w ${DIR} -n ${TREENAME} -# 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WITHOUT PARTITIONING\n",
    "\n",
    "### Using the alignment, build the tree with PhyML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/bin/python3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/kgilbert/Documents/UNIL/PartitioningMethods_SimulationProject',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python37.zip',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages',\n",
       " '/Users/kgilbert/Documents/UNIL/zoo',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/kgilbert/.ipython']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/bin/jupyter\r\n"
     ]
    }
   ],
   "source": [
    "!which jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PATH issues all fixed now, updated bash+profile and restarted jupyter\n",
    "\n",
    "#!echo $PATH\n",
    "\n",
    "#cwd = os.getcwd()\n",
    "#print(cwd)\n",
    "\n",
    "\n",
    "#!export PATH=$PATH:/Users/kgilbert/Documents/UNIL/phyml/src/\n",
    "    \n",
    "#!echo $PATH\n",
    "\n",
    "#sys.path.append('/Users/kgilbert/Documents/UNIL/phyml/src/')\n",
    "\n",
    "#!echo $PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree = Phyml(msa, datatype=\"PROTEIN\")#, binary='/Users/kgilbert/Documents/UNIL/phyml/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "phy_res = tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/------------------------------------------------------------------- S004/00001\n",
      "|                                                                              \n",
      "|                                                            /------ S024/00001\n",
      "|------------------------------------------------------------+                 \n",
      "|                                                            \\------ S021/00001\n",
      "|                                                                              \n",
      "|                                       /--------------------------- S019/00001\n",
      "|                                       |                                      \n",
      "|            /--------------------------+      /-------------------- S023/00001\n",
      "|            |                          |      |                               \n",
      "|            |                          \\------+             /------ S027/00001\n",
      "|            |                                 |      /------+                 \n",
      "|            |                                 |      |      \\------ S001/00001\n",
      "|            |                                 \\------+                        \n",
      "|            |                                        |      /------ S025/00001\n",
      "|            |                                        \\------+                 \n",
      "|            |                                               \\------ S026/00001\n",
      "|     /------+                                                                 \n",
      "+     |      |                                               /------ S003/00001\n",
      "|     |      |      /----------------------------------------+                 \n",
      "|     |      |      |                                        \\------ S022/00001\n",
      "|     |      |      |                                                          \n",
      "|     |      |      |                                        /------ S016/00001\n",
      "|     |      |      |                          /-------------+                 \n",
      "|     |      |      |                          |             \\------ S008/00001\n",
      "|     |      |      |                          |                               \n",
      "|     |      \\------+      /-------------------+             /------ S013/00001\n",
      "|     |             |      |                   |      /------+                 \n",
      "|     |             |      |                   |      |      \\------ S010/00001\n",
      "|     |             |      |                   \\------+                        \n",
      "|     |             |      |                          |      /------ S018/00001\n",
      "|     |             |      |                          \\------+                 \n",
      "|     |             |      |                                 \\------ S006/00001\n",
      "|     |             \\------+                                                   \n",
      "|     |                    |                                 /------ S030/00001\n",
      "|     |                    |                          /------+                 \n",
      "|     |                    |                          |      \\------ S007/00001\n",
      "\\-----+                    |      /-------------------+                        \n",
      "      |                    |      |                   |      /------ S028/00001\n",
      "      |                    |      |                   \\------+                 \n",
      "      |                    |      |                          \\------ S029/00001\n",
      "      |                    \\------+                                            \n",
      "      |                           |     /--------------------------- S005/00001\n",
      "      |                           |     |                                      \n",
      "      |                           |     |             /------------- S015/00001\n",
      "      |                           \\-----+      /------+                        \n",
      "      |                                 |      |      |      /------ S020/00001\n",
      "      |                                 |      |      \\------+                 \n",
      "      |                                 \\------+             \\------ S009/00001\n",
      "      |                                        |                               \n",
      "      |                                        |      /------------- S012/00001\n",
      "      |                                        \\------+                        \n",
      "      |                                               |      /------ S014/00001\n",
      "      |                                               \\------+                 \n",
      "      |                                                      \\------ S017/00001\n",
      "      |                                                                        \n",
      "      |                                                      /------ S002/00001\n",
      "      \\------------------------------------------------------+                 \n",
      "                                                             \\------ S011/00001\n",
      "                                                                               \n",
      "                                                                               \n"
     ]
    }
   ],
   "source": [
    "phy_res.print_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the alignment, build the tree with RAxML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raxmltree = Raxml(msa, datatype=\"PROTEIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No match found for \"alpha:\" (at char 0), (line:1, col:1)\n"
     ]
    }
   ],
   "source": [
    "rax_res = raxmltree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              /----- S025/00001\n",
      "     /--------------------------------------------------------+                \n",
      "     |                                                        \\----- S026/00001\n",
      "     |                                                                         \n",
      "     |     /-------------------------------------------------------- S023/00001\n",
      "     |     |                                                                   \n",
      "     |     |                                            /----------- S004/00001\n",
      "     |     |                                       /----+                      \n",
      "     |     |                                       |    |     /----- S021/00001\n",
      "     |     |                                       |    \\-----+                \n",
      "     |     |          /----------------------------+          \\----- S024/00001\n",
      "/----+     |          |                            |                           \n",
      "|    |     |          |                            |          /----- S002/00001\n",
      "|    |     |          |                            \\----------+                \n",
      "|    |     |          |                                       \\----- S011/00001\n",
      "|    |     |          |                                                        \n",
      "|    |     |          |                            /---------------- S029/00001\n",
      "|    |     |          |                /-----------+                           \n",
      "|    |     |          |                |           |    /----------- S028/00001\n",
      "|    |     |          |                |           \\----+                      \n",
      "|    |     |          |                |                |     /----- S007/00001\n",
      "|    \\-----+          |                |                \\-----+                \n",
      "|          |          |           /----+                      \\----- S030/00001\n",
      "|          |          |           |    |                                       \n",
      "|          |          |           |    |     /---------------------- S005/00001\n",
      "|          |     /----+           |    |     |                                 \n",
      "|          |     |    |           |    |     |                /----- S020/00001\n",
      "|          |     |    |           |    \\-----+          /-----+                \n",
      "|          |     |    |           |          |     /----+     \\----- S009/00001\n",
      "|          |     |    |           |          |     |    |                      \n",
      "|          |     |    |           |          \\-----+    \\----------- S015/00001\n",
      "|          |     |    |           |                |                           \n",
      "|          |     |    |     /-----+                |    /----------- S012/00001\n",
      "|          |     |    |     |     |                \\----+                      \n",
      "+          |     |    |     |     |                     |     /----- S014/00001\n",
      "|          |     |    |     |     |                     \\-----+                \n",
      "|          |     |    |     |     |                           \\----- S017/00001\n",
      "|          |     |    |     |     |                                            \n",
      "|          |     |    |     |     |                           /----- S008/00001\n",
      "|          \\-----+    |     |     |                /----------+                \n",
      "|                |    |     |     |                |          \\----- S016/00001\n",
      "|                |    \\-----+     |                |                           \n",
      "|                |          |     \\----------------+          /----- S010/00001\n",
      "|                |          |                      |    /-----+                \n",
      "|                |          |                      |    |     \\----- S013/00001\n",
      "|                |          |                      \\----+                      \n",
      "|                |          |                           |     /----- S006/00001\n",
      "|                |          |                           \\-----+                \n",
      "|                |          |                                 \\----- S018/00001\n",
      "|                |          |                                                  \n",
      "|                |          |                                 /----- S022/00001\n",
      "|                |          \\---------------------------------+                \n",
      "|                |                                            \\----- S003/00001\n",
      "|                |                                                             \n",
      "|                \\-------------------------------------------------- S019/00001\n",
      "|                                                                              \n",
      "|------------------------------------------------------------------- S027/00001\n",
      "|                                                                              \n",
      "\\------------------------------------------------------------------- S001/00001\n",
      "                                                                               \n",
      "                                                                               \n"
     ]
    }
   ],
   "source": [
    "#rax_res.values()\n",
    "\n",
    "rax_res['tree'].print_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the alignment, build the tree with IQTree\n",
    "\n",
    "For input to IQtree, must have a partition file in RAxML or NEXUS format\n",
    "for NEXUS, each partition could come from a separate alignment file; this is not possible for RAxML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqtree = Iqtree(msa, datatype=\"PROTEIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_res = iqtree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/------------------------------------------------------------------- S001 00001\n",
      "|                                                                              \n",
      "|                                                             /----- S002 00001\n",
      "|                                                  /----------+                \n",
      "|                                                  |          \\----- S011 00001\n",
      "|                     /----------------------------+                           \n",
      "|                     |                            |    /----------- S004 00001\n",
      "|                     |                            \\----+                      \n",
      "|                     |                                 |     /----- S021 00001\n",
      "|                     |                                 \\-----+                \n",
      "|                     |                                       \\----- S024 00001\n",
      "|                     |                                                        \n",
      "|                     |                                       /----- S003 00001\n",
      "|                     |     /---------------------------------+                \n",
      "|                /----+     |                                 \\----- S022 00001\n",
      "|                |    |     |                                                  \n",
      "|                |    |     |                /---------------------- S005 00001\n",
      "|                |    |     |                |                                 \n",
      "|                |    |     |                |                /----- S009 00001\n",
      "|                |    |     |          /-----+          /-----+                \n",
      "|                |    |     |          |     |     /----+     \\----- S020 00001\n",
      "|                |    |     |          |     |     |    |                      \n",
      "|                |    |     |          |     \\-----+    \\----------- S015 00001\n",
      "|                |    |     |          |           |                           \n",
      "|                |    \\-----+          |           |    /----------- S012 00001\n",
      "|                |          |          |           \\----+                      \n",
      "|                |          |     /----+                |     /----- S014 00001\n",
      "|                |          |     |    |                \\-----+                \n",
      "|                |          |     |    |                      \\----- S017 00001\n",
      "+                |          |     |    |                                       \n",
      "|                |          |     |    |                      /----- S007 00001\n",
      "|                |          |     |    |                /-----+                \n",
      "|          /-----+          |     |    |                |     \\----- S030 00001\n",
      "|          |     |          |     |    \\----------------+                      \n",
      "|          |     |          |     |                     |     /----- S028 00001\n",
      "|          |     |          \\-----+                     \\-----+                \n",
      "|          |     |                |                           \\----- S029 00001\n",
      "|          |     |                |                                            \n",
      "|          |     |                |                           /----- S006 00001\n",
      "|          |     |                |                     /-----+                \n",
      "|          |     |                |                     |     \\----- S018 00001\n",
      "|          |     |                |                /----+                      \n",
      "|    /-----+     |                |                |    |     /----- S010 00001\n",
      "|    |     |     |                |                |    \\-----+                \n",
      "|    |     |     |                \\----------------+          \\----- S013 00001\n",
      "|    |     |     |                                 |                           \n",
      "|    |     |     |                                 |          /----- S008 00001\n",
      "|    |     |     |                                 \\----------+                \n",
      "|----+     |     |                                            \\----- S016 00001\n",
      "|    |     |     |                                                             \n",
      "|    |     |     \\-------------------------------------------------- S019 00001\n",
      "|    |     |                                                                   \n",
      "|    |     \\-------------------------------------------------------- S023 00001\n",
      "|    |                                                                         \n",
      "|    |                                                        /----- S025 00001\n",
      "|    \\--------------------------------------------------------+                \n",
      "|                                                             \\----- S026 00001\n",
      "|                                                                              \n",
      "\\------------------------------------------------------------------- S027 00001\n",
      "                                                                               \n",
      "                                                                               \n"
     ]
    }
   ],
   "source": [
    "# old way before Adrian updated the wrapper:\n",
    "# iqtree_res = dendropy.Tree.get(data=iq_res, schema='newick')\n",
    "iq_res['tree'].print_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now I can build all the trees, next need to use partitioning methods to see if/when we get better/worse trees depending on the AIC/BIC values\n",
    "\n",
    "Lanfear et al 2008, MBE has PartitionFinder (v1 and v2)\n",
    "\n",
    "You have to a priori define the number of data blocks? Which then creates the potential number of partitioning schemes..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IQTree uses partition methods during its tree building (different above?) so that would combine steps 2 and 3\n",
    "still have to define where the partitions are a priori\n",
    "3 types of partition models:\n",
    "* edge-equal -- branch lengths same across all branches\n",
    "* edge-proportional -- each partition has its own specific rate that rescales all of its branch lengths, i.e. diff. evolutionary rates between partitions\n",
    "* edge-unlinked -- most parameter-rich model, each partition has its own set of branch lengths\n",
    "they recommend edge-proportional, saying the 3rd might overfit and the 1st does not allow variation in speeds btwn partitions (so what does it allow????)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOT USING ANY Of THIS CURRENTLY\n",
    "\n",
    "\n",
    "#unalign_msa_dir = 'unaligned_MSA/'\n",
    "# right now, 200 .fa files\n",
    "#  infile = r\"MSA_1_aa.fa\"\n",
    "#  outfile = r\"unaligned_MSA_1_aa.fa\"# un-align them (remove the \"-\" from all locations in all files)\n",
    "\n",
    "# one way of doing it with a loop\n",
    "#for i in range(1,5):  # change to 201 to do all 200 files\n",
    "#    infile = \"%sMSA_%d_aa.fa\" % (alf_msa_dir, i)\n",
    "#    #print(infile)\n",
    "#    outfile = r\"%sunaligned_MSA_%d_aa.fa\" % (unalign_msa_dir, i)\n",
    "#    \n",
    "#    fin = open(infile,\"r\")\n",
    "#    fout = open(outfile,\"w+\")\n",
    "#    for line in fin:\n",
    "#        line = line.replace(\"-\", \"\")\n",
    "#        fout.write(line)\n",
    "#    fin.close()\n",
    "#    fout.close()\n",
    "#    print(i)\n",
    "\n",
    "# fancier way of doing it, ala Christophe's code in treebuilding tutorial\n",
    "# for file in os.listdir(alf_msa_dir):\n",
    "#     if file.endswith(\".fa\"):\n",
    "#         print(file)\n",
    "#         infile = AlignIO.read(alf_msa_dir+'/'+file, \"fasta\")\n",
    "#         outfile = unalign_msa_dir+'/'+file\n",
    "#      \n",
    "#         fin = open(infile,\"r\") ## THIS PART DOESN'T WORK, bc it is already in MSA format?\n",
    "#         fout = open(outfile,\"w+\")\n",
    "#         for line in fin:\n",
    "#             line = line.replace(\"-\", \"\")\n",
    "#             fout.write(line)\n",
    "#         fin.close()\n",
    "#         fout.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the inferred trees match the true tree?\n",
    "### How to assess whether the trees are better recovered or not with partitioning/better AIC/BIC\n",
    "\n",
    "- monophyly score - a measure of how well a phylogenetic tree recoveres monophyletic lineages\n",
    "- Robinson Foulds distance - captures the variance in the best tree generated; looks at what inner groups are kept in some paritions?\n",
    "\n",
    "Provide the Newick tree, and Jeremy had scripts that then calculate the two above measures. Needs a clade(???) file? I think this is just a list of all the samples, which for me would be the number of simulated species. Plus the Newick tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeremy - Robinson-Foulds script\n",
    "\"\"\"\n",
    "Calculates RF distances between two trees\n",
    "\"\"\"\n",
    "\n",
    "from ete3 import Tree\n",
    "\n",
    "def collapse_branches(TREE_FILE,SUPPORT_THRESHOLD):\n",
    "    t = Tree(TREE_FILE)\n",
    "    for node in t.get_descendants():\n",
    "        if not node.is_leaf() and (node.support <= SUPPORT_THRESHOLD):\n",
    "            node.delete()\n",
    "    return t\n",
    "\n",
    "\n",
    "def count_internal(tree):\n",
    "    tree.unroot()\n",
    "    edges=-1\n",
    "    for edge in tree.traverse():\n",
    "        if not edge.is_leaf():\n",
    "            edges+=1\n",
    "    return edges\n",
    "\n",
    "def rf_distance(tree1,tree2,option=False):\n",
    "#    if option=='collapse':\n",
    "#        t1 = collapse_branches(tree1,0.75)\n",
    "#        t2 = collapse_branches(tree2,0.75)\n",
    "#        option = 'reduced'\n",
    "#    else:\n",
    "#        t1 = Tree(tree1)\n",
    "#        t2 = Tree(tree2)\n",
    "\n",
    "    t1.unroot()\n",
    "    t2.unroot()\n",
    "\n",
    "    rf = t1.robinson_foulds(t2,unrooted_trees=True)\n",
    "\n",
    "    rf_dist = rf[0]\n",
    "    max_rf = rf[1]\n",
    "    num_leaves=len(rf[2])\n",
    "\n",
    "    max_resolved_score = (2*num_leaves)-6\n",
    "\n",
    "    internal_branches_t1 = count_internal(t1)\n",
    "    internal_branches_t2 = count_internal(t2)\n",
    "\n",
    "    total_internal = internal_branches_t1 + internal_branches_t2\n",
    "\n",
    "    num_missing_splits_t1 = num_leaves - 3 - internal_branches_t1\n",
    "    num_missing_splits_t2 = num_leaves - 3 - internal_branches_t2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    rf_dist_upper = rf_dist + num_missing_splits_t1 + num_missing_splits_t2\n",
    "\n",
    "\n",
    "    #If normalise by (num intenral branches)\n",
    "    if option=='reduced':\n",
    "        normalised_rf = rf_dist/total_internal\n",
    "\n",
    "    elif option=='upper':\n",
    "    #If add score to create upper bound due to being polytomy\n",
    "        normalised_rf = rf_dist_upper/max_resolved_score\n",
    "    else:\n",
    "        normalised_rf = rf_dist/max_resolved_score\n",
    "\n",
    "    return normalised_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compare these two trees\n",
    "# later on --- use the actual tree from ALF sims...\n",
    "\n",
    "#print(phy_res)\n",
    "\n",
    "#print('\\n')\n",
    "\n",
    "#print(iqtree_res)\n",
    "\n",
    "#print(rax_res['tree'])\n",
    "\n",
    "## NEED TO APPEND A ';' TO THE TREE STRINGS, CAN'T SEEM TO DO THIS TO THE TREE FORMAT within python?\n",
    "# write each tree to a file and then read from there for RF calcs\n",
    "\n",
    "with open('iqtree.nw', 'w') as f:\n",
    "    print(iq_res['tree'], \";\", file=f)\n",
    "\n",
    "with open('phyml.nw', 'w') as f:\n",
    "    print(phy_res, \";\", file=f)\n",
    "\n",
    "with open('raxml.nw', 'w') as f:\n",
    "    print(rax_res['tree'], \";\", file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = Tree (\"results/222dc49d-452f-43bf-a968-90e4fa814b6e/RealTree.nwk\")\n",
    "\n",
    "t1 = Tree(\"iqtree.nw\")\n",
    "t2 = Tree(\"phyml.nw\")\n",
    "t3 = Tree(\"raxml.nw\")\n",
    "\n",
    "t4=Tree(\"test_out.txt\")\n",
    "\n",
    "#print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the RF script to my trees; compare original simulated tree to each inferred tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_distance(t0, t1) # vs iqtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_distance(t0, t2) # vs phyml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_distance(t0, t3) # vs raxml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TestingPartitioningMethods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
