{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ALF simulations\n",
    "\n",
    "- two datasets\n",
    "- same number of species as in Jeremy's empirical dataset\n",
    "\n",
    "### Other parameters currently:\n",
    "\n",
    "unitIsPam := true:\n",
    "\n",
    "#### orig parameters concerning the root genome\n",
    "realseed := false;\n",
    "protStart := 200;\n",
    "minGeneLength := 50;\n",
    "gammaLengthDist := [3, 133.8063];\n",
    "blocksize := 1:\n",
    "\n",
    "#### new parameters concerning the root genome where each gene is 50 long\n",
    "realseed := false;\n",
    "protStart := 100;\n",
    "minGeneLength := 50;\n",
    "gammaLengthDist := [1, 1];\n",
    "blocksize := 1:\n",
    "\n",
    "#### parameters concerning the species tree\n",
    "treeType := 'BDTree';\n",
    "birthRate := 0.01;\n",
    "deathRate := 0.001;\n",
    "NSpecies := 25;\n",
    "ultrametric := false;\n",
    "mutRate := 250;\n",
    "scaleTree := true;\n",
    "\n",
    "#### parameters concerning the substitution models\n",
    "substModels := [SubstitutionModel('LG')];\n",
    "indelModels := [IndelModel(0.0001, ZIPF, [1.821], 50)];\n",
    "rateVarModels := [RateVarModel()];\n",
    "modelAssignments := [1]:\n",
    "modelSwitchS := [[1]]:\n",
    "modelSwitchD := [[1]]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /usr/local/bin/../lib/simulator/splashscreen.txt: No such file or directory\n",
      "Darwin: Sequence Searching Facility\n",
      "Version 4.0, 2014-02-21\n",
      "  (c) E.T.H. Zurich\n",
      "> paramfile := 'alf-params_lopho.drw': wdir := './': ReadProgram(libname.'/simulator/evolstart.drw'): done:\n",
      "\n",
      "IO procedures for Synthetic Evolution sucessfully loaded\n",
      "Procedures for Genome Rearrangement sucessfully loaded\n",
      "Procedures for Synthetic Evolution sucessfully loaded\n",
      "\n",
      "\n",
      "parameter file read\n",
      "setting up work directory\n",
      "determining tree\n",
      "\n",
      "tree loaded\n",
      "model assignments done\n",
      "\n",
      "\n",
      "Evolution!\n",
      "\n",
      "\n",
      "species 2 was created at time 0.0000\n",
      "species 3 was created at time 5.6069\n",
      "species 4 was created at time 8.1724\n",
      "species 5 was created at time 20.1927\n",
      "species 6 was created at time 20.4022\n",
      "species 7 was created at time 24.7324\n",
      "species 8 was created at time 31.5959\n",
      "species 9 was created at time 34.3569\n",
      "species 10 was created at time 38.3768\n",
      "species 11 was created at time 38.5539\n",
      "species 12 was created at time 38.5693\n",
      "species 13 was created at time 39.8331\n",
      "species 14 was created at time 42.5714\n",
      "species 15 was created at time 46.6566\n",
      "species 16 was created at time 46.6649\n",
      "species 17 was created at time 58.1306\n",
      "species 18 was created at time 60.7246\n",
      "species 19 was created at time 67.6505\n",
      "species 20 was created at time 69.2720\n",
      "species 21 was created at time 69.9359\n",
      "species 22 was created at time 70.9319\n",
      "species 23 was created at time 72.6639\n",
      "species 24 was created at time 78.8982\n",
      "species 25 was created at time 79.7118\n",
      "species 26 was created at time 82.7712\n",
      "species 27 was created at time 83.5532\n",
      "species 28 was created at time 83.9936\n",
      "species 29 was created at time 86.2772\n",
      "species 30 was created at time 89.9014\n",
      "species 31 was created at time 90.9715\n",
      "species 32 was created at time 92.6267\n",
      "species 33 was created at time 94.9757\n",
      "species 34 was created at time 95.9083\n",
      "species 35 was created at time 96.5067\n",
      "species 36 was created at time 102.3803\n",
      "species 37 was created at time 104.7805\n",
      "species 38 was created at time 106.2473\n",
      "species 39 was created at time 106.6223\n",
      "species 40 was created at time 110.2829\n",
      "species 41 was created at time 110.6490\n",
      "species 42 was created at time 111.2889\n",
      "species 43 was created at time 114.7968\n",
      "species 44 was created at time 115.3535\n",
      "species 45 was created at time 117.3124\n",
      "species 46 was created at time 118.1263\n",
      "species 47 was created at time 119.3102\n",
      "species 48 was created at time 119.3784\n",
      "species 49 was created at time 119.5951\n",
      "species 50 was created at time 119.6374\n",
      "species 51 was created at time 123.2984\n",
      "species 52 was created at time 123.3115\n",
      "species 53 was created at time 125.4127\n",
      "species 54 was created at time 140.2695\n",
      "species 55 was created at time 152.8550\n",
      "species 56 was created at time 157.3222\n",
      "species 57 was created at time 159.7174\n",
      "species 58 was created at time 163.9916\n",
      "species 59 was created at time 168.4402\n",
      "species 60 was created at time 173.6779\n",
      "species 61 was created at time 202.2455\n",
      "species 62 was created at time 217.7874\n",
      "...real genome tree saved.\n",
      "...main calculation finished after 0.12 minutes.\n",
      "tar: Option --remove-files is not supported\n",
      "Usage:\n",
      "  List:    tar -tf <archive-filename>\n",
      "  Extract: tar -xf <archive-filename>\n",
      "  Create:  tar -cf <archive-filename> [filenames...]\n",
      "  Help:    tar --help\n",
      "...pairwise relationships written.\n",
      "...gene trees written.\n",
      "...real MSAs written.\n",
      "\n",
      "\n",
      ".db files written...\n",
      "\n",
      "\n",
      "Reading 22049 characters from file ./results_lopho//sim_match_lophotroch/DB/SE001.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE001.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE001.db.tree with 4988 entries\n",
      "Pat index with 4988 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYTIF</SEQ></E>\\n<E>\"\n",
      "Reading 22835 characters from file ./results_lopho//sim_match_lophotroch/DB/SE002.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE002.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE002.db.tree with 5033 entries\n",
      "Pat index with 5033 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYTASEAIADICHEDTSKQ\"\n",
      "Reading 28354 characters from file ./results_lopho//sim_match_lophotroch/DB/SE003.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE003.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE003.db.tree with 5157 entries\n",
      "Pat index with 5157 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYSIVLRGFTLALGDENKR\"\n",
      "Reading 26952 characters from file ./results_lopho//sim_match_lophotroch/DB/SE004.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE004.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE004.db.tree with 4985 entries\n",
      "Pat index with 4985 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYTSMAF</SEQ></E>\\n<\"\n",
      "Reading 28001 characters from file ./results_lopho//sim_match_lophotroch/DB/SE005.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE005.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE005.db.tree with 5018 entries\n",
      "Pat index with 5018 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYSLIHLIAK</SEQ></E\"\n",
      "Reading 26758 characters from file ./results_lopho//sim_match_lophotroch/DB/SE006.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE006.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE006.db.tree with 5032 entries\n",
      "Pat index with 5032 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYDVIKCGMDDKAVK</SE\"\n",
      "Reading 29238 characters from file ./results_lopho//sim_match_lophotroch/DB/SE007.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE007.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE007.db.tree with 5030 entries\n",
      "Pat index with 5030 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVVYALQVLLKKFRSYHF\"\n",
      "Reading 31544 characters from file ./results_lopho//sim_match_lophotroch/DB/SE008.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE008.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE008.db.tree with 5035 entries\n",
      "Pat index with 5035 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYIGVNGIDLMTL</SEQ>\"\n",
      "Reading 27707 characters from file ./results_lopho//sim_match_lophotroch/DB/SE009.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE009.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE009.db.tree with 5019 entries\n",
      "Pat index with 5019 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYYLMSRLLFWRNWSQGHG\"\n",
      "Reading 29110 characters from file ./results_lopho//sim_match_lophotroch/DB/SE010.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE010.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE010.db.tree with 4989 entries\n",
      "Pat index with 4989 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVLQEYEDQVIEMIRPML\"\n",
      "Reading 30184 characters from file ./results_lopho//sim_match_lophotroch/DB/SE011.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE011.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE011.db.tree with 4942 entries\n",
      "Pat index with 4942 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYLEAWLEEPKSSPLLGWT\"\n",
      "Reading 30190 characters from file ./results_lopho//sim_match_lophotroch/DB/SE012.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE012.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE012.db.tree with 4965 entries\n",
      "Pat index with 4965 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYEHM</SEQ></E>\\n<E>\"\n",
      "Reading 27624 characters from file ./results_lopho//sim_match_lophotroch/DB/SE013.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE013.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE013.db.tree with 5017 entries\n",
      "Pat index with 5017 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYTHRNDKLSTVGYLTPQE\"\n",
      "Reading 30350 characters from file ./results_lopho//sim_match_lophotroch/DB/SE014.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE014.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE014.db.tree with 5041 entries\n",
      "Pat index with 5041 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYQL</SEQ></E>\\n<E><\"\n",
      "Reading 33613 characters from file ./results_lopho//sim_match_lophotroch/DB/SE015.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE015.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE015.db.tree with 4984 entries\n",
      "Pat index with 4984 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVNLKRFQLRSL</SEQ>\"\n",
      "Reading 33326 characters from file ./results_lopho//sim_match_lophotroch/DB/SE016.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE016.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE016.db.tree with 4923 entries\n",
      "Pat index with 4923 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYQVQPVIAVASVGQRFAE\"\n",
      "Reading 24673 characters from file ./results_lopho//sim_match_lophotroch/DB/SE017.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE017.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE017.db.tree with 4960 entries\n",
      "Pat index with 4960 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYNRDKPAVFALRSAITDS\"\n",
      "Reading 30993 characters from file ./results_lopho//sim_match_lophotroch/DB/SE018.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE018.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE018.db.tree with 4935 entries\n",
      "Pat index with 4935 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYTTSSYRNLVFGGLAPRP\"\n",
      "Reading 32229 characters from file ./results_lopho//sim_match_lophotroch/DB/SE019.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE019.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE019.db.tree with 5109 entries\n",
      "Pat index with 5109 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVEVDYDDRSDPSTAATV\"\n",
      "Reading 24928 characters from file ./results_lopho//sim_match_lophotroch/DB/SE020.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE020.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE020.db.tree with 4982 entries\n",
      "Pat index with 4982 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYTIF</SEQ></E>\\n<E>\"\n",
      "Reading 30633 characters from file ./results_lopho//sim_match_lophotroch/DB/SE021.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE021.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE021.db.tree with 4958 entries\n",
      "Pat index with 4958 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYTTSNDSLSNAGYLRPQE\"\n",
      "Reading 33119 characters from file ./results_lopho//sim_match_lophotroch/DB/SE022.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE022.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE022.db.tree with 4951 entries\n",
      "Pat index with 4951 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYTHSNEKLPVAGYLTPQE\"\n",
      "Reading 36783 characters from file ./results_lopho//sim_match_lophotroch/DB/SE023.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE023.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE023.db.tree with 4922 entries\n",
      "Pat index with 4922 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYTHVQQAHPPSYATDSGL\"\n",
      "Reading 32448 characters from file ./results_lopho//sim_match_lophotroch/DB/SE024.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE024.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE024.db.tree with 4981 entries\n",
      "Pat index with 4981 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYMKRKRVLSKKASGFRNN\"\n",
      "Reading 33312 characters from file ./results_lopho//sim_match_lophotroch/DB/SE025.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE025.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE025.db.tree with 4932 entries\n",
      "Pat index with 4932 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYRLQVFK</SEQ></E>\\n\"\n",
      "Reading 33649 characters from file ./results_lopho//sim_match_lophotroch/DB/SE026.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE026.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE026.db.tree with 4965 entries\n",
      "Pat index with 4965 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVLRGAIETTGLAVD</S\"\n",
      "Reading 31174 characters from file ./results_lopho//sim_match_lophotroch/DB/SE027.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE027.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE027.db.tree with 5091 entries\n",
      "Pat index with 5091 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVSILLALNNASKSEGR<\"\n",
      "Reading 33497 characters from file ./results_lopho//sim_match_lophotroch/DB/SE028.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE028.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE028.db.tree with 4985 entries\n",
      "Pat index with 4985 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVHSNDSLSTTGYIRPQE\"\n",
      "Reading 36387 characters from file ./results_lopho//sim_match_lophotroch/DB/SE029.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE029.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE029.db.tree with 4925 entries\n",
      "Pat index with 4925 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVLRGAIETTGLAVD</S\"\n",
      "Reading 30833 characters from file ./results_lopho//sim_match_lophotroch/DB/SE030.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE030.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE030.db.tree with 5081 entries\n",
      "Pat index with 5081 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVEAKL</SEQ></E>\\n<\"\n",
      "Reading 34626 characters from file ./results_lopho//sim_match_lophotroch/DB/SE031.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE031.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE031.db.tree with 5128 entries\n",
      "Pat index with 5128 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVLRISNLNDTFDGWVNV\"\n",
      "Reading 32246 characters from file ./results_lopho//sim_match_lophotroch/DB/SE032.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE032.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE032.db.tree with 4992 entries\n",
      "Pat index with 4992 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVMRGQADSIGLNAD</S\"\n",
      "Reading 36069 characters from file ./results_lopho//sim_match_lophotroch/DB/SE033.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE033.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE033.db.tree with 4974 entries\n",
      "Pat index with 4974 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYKIPDGRHELSEALHADL\"\n",
      "Reading 30594 characters from file ./results_lopho//sim_match_lophotroch/DB/SE034.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE034.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE034.db.tree with 5075 entries\n",
      "Pat index with 5075 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYTAKHSKIRMINPIPMSV\"\n",
      "Reading 36287 characters from file ./results_lopho//sim_match_lophotroch/DB/SE035.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE035.db.map for mapping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE035.db.tree with 4983 entries\n",
      "Pat index with 4983 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYPTTKVGKSATKGSVRKA\"\n",
      "Reading 32045 characters from file ./results_lopho//sim_match_lophotroch/DB/SE036.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE036.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE036.db.tree with 4998 entries\n",
      "Pat index with 4998 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYYVSPHTLVIDPNILGQK\"\n",
      "Reading 30572 characters from file ./results_lopho//sim_match_lophotroch/DB/SE037.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE037.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE037.db.tree with 5015 entries\n",
      "Pat index with 5015 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYYLTSRLLFWRNWSAGHG\"\n",
      "Reading 32576 characters from file ./results_lopho//sim_match_lophotroch/DB/SE038.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE038.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE038.db.tree with 5013 entries\n",
      "Pat index with 5013 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYYVSPHTLIISPNIVGQQ\"\n",
      "Reading 33075 characters from file ./results_lopho//sim_match_lophotroch/DB/SE039.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE039.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE039.db.tree with 5036 entries\n",
      "Pat index with 5036 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVVYAVQVLLKRSRSYYL\"\n",
      "Reading 34979 characters from file ./results_lopho//sim_match_lophotroch/DB/SE040.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE040.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE040.db.tree with 5043 entries\n",
      "Pat index with 5043 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYYVSPHTMLIDPNIVGRS\"\n",
      "Reading 35808 characters from file ./results_lopho//sim_match_lophotroch/DB/SE041.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE041.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE041.db.tree with 4978 entries\n",
      "Pat index with 4978 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYRLAGRENIVLGWCAPVQ\"\n",
      "Reading 32076 characters from file ./results_lopho//sim_match_lophotroch/DB/SE042.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE042.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE042.db.tree with 5028 entries\n",
      "Pat index with 5028 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVVYSFKVLLKRFRSYHY\"\n",
      "Reading 32904 characters from file ./results_lopho//sim_match_lophotroch/DB/SE043.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE043.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE043.db.tree with 5028 entries\n",
      "Pat index with 5028 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYLVKNHQETSYLYIRMKI\"\n",
      "Reading 35556 characters from file ./results_lopho//sim_match_lophotroch/DB/SE044.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE044.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE044.db.tree with 4992 entries\n",
      "Pat index with 4992 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYLVKSKQASSNMFIRMKL\"\n",
      "Reading 37326 characters from file ./results_lopho//sim_match_lophotroch/DB/SE045.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE045.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE045.db.tree with 5139 entries\n",
      "Pat index with 5139 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVLRISPLNDTLDGWVAV\"\n",
      "Reading 30803 characters from file ./results_lopho//sim_match_lophotroch/DB/SE046.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE046.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE046.db.tree with 5013 entries\n",
      "Pat index with 5013 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYTHERSTKVDLVGQLFH<\"\n",
      "Reading 34845 characters from file ./results_lopho//sim_match_lophotroch/DB/SE047.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE047.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE047.db.tree with 4998 entries\n",
      "Pat index with 4998 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYYVSPHTLVIDPNILGQK\"\n",
      "Reading 29967 characters from file ./results_lopho//sim_match_lophotroch/DB/SE048.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE048.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE048.db.tree with 5008 entries\n",
      "Pat index with 5008 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYSVLVLSRAKKLLTVAGY\"\n",
      "Reading 35067 characters from file ./results_lopho//sim_match_lophotroch/DB/SE049.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE049.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE049.db.tree with 5026 entries\n",
      "Pat index with 5026 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYYVGPHTLVISPNIPTGV\"\n",
      "Reading 33086 characters from file ./results_lopho//sim_match_lophotroch/DB/SE050.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE050.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE050.db.tree with 5033 entries\n",
      "Pat index with 5033 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYLVEHLLEPAEENKIKHA\"\n",
      "Reading 37788 characters from file ./results_lopho//sim_match_lophotroch/DB/SE051.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE051.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE051.db.tree with 5011 entries\n",
      "Pat index with 5011 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYYVSPHTLVISPNIVGQQ\"\n",
      "Reading 34865 characters from file ./results_lopho//sim_match_lophotroch/DB/SE052.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE052.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE052.db.tree with 5035 entries\n",
      "Pat index with 5035 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVVYSFKVLLKRFRSYHY\"\n",
      "Reading 34876 characters from file ./results_lopho//sim_match_lophotroch/DB/SE053.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE053.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE053.db.tree with 5028 entries\n",
      "Pat index with 5028 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVVYSFKVLLKRFRSYHY\"\n",
      "Reading 34335 characters from file ./results_lopho//sim_match_lophotroch/DB/SE054.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE054.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE054.db.tree with 4959 entries\n",
      "Pat index with 4959 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYWMAAKVFSMMKDDNPIT\"\n",
      "Reading 34448 characters from file ./results_lopho//sim_match_lophotroch/DB/SE055.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE055.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE055.db.tree with 5096 entries\n",
      "Pat index with 5096 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVEVDYNDRSPPAHAASV\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 34773 characters from file ./results_lopho//sim_match_lophotroch/DB/SE056.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE056.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE056.db.tree with 4932 entries\n",
      "Pat index with 4932 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYSRYTDVTKKIREHLVAK\"\n",
      "Reading 35881 characters from file ./results_lopho//sim_match_lophotroch/DB/SE057.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE057.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE057.db.tree with 5028 entries\n",
      "Pat index with 5028 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYLVEHLLEPAEENKIKHA\"\n",
      "Reading 38606 characters from file ./results_lopho//sim_match_lophotroch/DB/SE058.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE058.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE058.db.tree with 4957 entries\n",
      "Pat index with 4957 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVEE</SEQ></E>\\n<E>\"\n",
      "Reading 41329 characters from file ./results_lopho//sim_match_lophotroch/DB/SE059.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE059.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE059.db.tree with 4948 entries\n",
      "Pat index with 4948 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVQE</SEQ></E>\\n<E>\"\n",
      "Reading 41652 characters from file ./results_lopho//sim_match_lophotroch/DB/SE060.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE060.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE060.db.tree with 4941 entries\n",
      "Pat index with 4941 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVQE</SEQ></E>\\n<E>\"\n",
      "Reading 35141 characters from file ./results_lopho//sim_match_lophotroch/DB/SE061.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE061.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE061.db.tree with 4984 entries\n",
      "Pat index with 4984 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYLPNFDRAASTDEKVPSD\"\n",
      "Reading 30923 characters from file ./results_lopho//sim_match_lophotroch/DB/SE062.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_lopho//sim_match_lophotroch/DB/SE062.db.map for mapping\n",
      "Building new Pat index in file ./results_lopho//sim_match_lophotroch/DB/SE062.db.tree with 5167 entries\n",
      "Pat index with 5167 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYSIVLRGFTLALGDENKR\"\n",
      "\n",
      "\n",
      ".fasta files written...\n",
      "\n",
      "\n",
      "...genome DBs saved.\n",
      "\n",
      "   simulation finished!\n",
      "\n",
      "\n",
      "synthetic evolution completed in 0.27 minutes!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!alfsim alf-params_lopho.drw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /usr/local/bin/../lib/simulator/splashscreen.txt: No such file or directory\n",
      "Darwin: Sequence Searching Facility\n",
      "Version 4.0, 2014-02-21\n",
      "  (c) E.T.H. Zurich\n",
      "> paramfile := 'alf-params_myria.drw': wdir := './': ReadProgram(libname.'/simulator/evolstart.drw'): done:\n",
      "\n",
      "IO procedures for Synthetic Evolution sucessfully loaded\n",
      "Procedures for Genome Rearrangement sucessfully loaded\n",
      "Procedures for Synthetic Evolution sucessfully loaded\n",
      "\n",
      "\n",
      "parameter file read\n",
      "setting up work directory\n",
      "determining tree\n",
      "\n",
      "tree loaded\n",
      "model assignments done\n",
      "\n",
      "\n",
      "Evolution!\n",
      "\n",
      "\n",
      "species 2 was created at time 0.0000\n",
      "species 3 was created at time 3.9724\n",
      "species 4 was created at time 5.3352\n",
      "species 5 was created at time 5.9740\n",
      "species 6 was created at time 6.1022\n",
      "species 7 was created at time 18.6187\n",
      "species 8 was created at time 19.2781\n",
      "species 9 was created at time 19.4129\n",
      "species 10 was created at time 20.0638\n",
      "species 11 was created at time 25.3307\n",
      "species 12 was created at time 38.7227\n",
      "species 13 was created at time 45.8687\n",
      "species 14 was created at time 50.6420\n",
      "species 15 was created at time 51.9868\n",
      "species 16 was created at time 63.1894\n",
      "species 17 was created at time 69.0804\n",
      "species 18 was created at time 69.5164\n",
      "species 19 was created at time 73.9739\n",
      "species 20 was created at time 76.0793\n",
      "species 21 was created at time 76.1347\n",
      "species 22 was created at time 82.0016\n",
      "species 23 was created at time 83.9751\n",
      "species 24 was created at time 108.0622\n",
      "species 25 was created at time 115.6847\n",
      "...real genome tree saved.\n",
      "...main calculation finished after 0.07 minutes.\n",
      "tar: Option --remove-files is not supported\n",
      "Usage:\n",
      "  List:    tar -tf <archive-filename>\n",
      "  Extract: tar -xf <archive-filename>\n",
      "  Create:  tar -cf <archive-filename> [filenames...]\n",
      "  Help:    tar --help\n",
      "...pairwise relationships written.\n",
      "...gene trees written.\n",
      "...real MSAs written.\n",
      "\n",
      "\n",
      ".db files written...\n",
      "\n",
      "\n",
      "Reading 21846 characters from file ./results_myria//sim_match_myriapod/DB/SE001.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE001.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE001.db.tree with 4977 entries\n",
      "Pat index with 4977 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYNLRTP</SEQ></E>\\n<\"\n",
      "Reading 22585 characters from file ./results_myria//sim_match_myriapod/DB/SE002.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE002.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE002.db.tree with 5078 entries\n",
      "Pat index with 5078 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYTFQETEAYE</SEQ></\"\n",
      "Reading 28098 characters from file ./results_myria//sim_match_myriapod/DB/SE003.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE003.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE003.db.tree with 4959 entries\n",
      "Pat index with 4959 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYLNKSRNFVVLRPDAACI\"\n",
      "Reading 26968 characters from file ./results_myria//sim_match_myriapod/DB/SE004.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE004.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE004.db.tree with 5049 entries\n",
      "Pat index with 5049 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVNQKGKDRKSTCRYVYF\"\n",
      "Reading 31096 characters from file ./results_myria//sim_match_myriapod/DB/SE005.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE005.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE005.db.tree with 4982 entries\n",
      "Pat index with 4982 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYRYEQRGTQS</SEQ></\"\n",
      "Reading 33067 characters from file ./results_myria//sim_match_myriapod/DB/SE006.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE006.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE006.db.tree with 4942 entries\n",
      "Pat index with 4942 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYRFQLSLATIEGDRPCEY\"\n",
      "Reading 24222 characters from file ./results_myria//sim_match_myriapod/DB/SE007.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE007.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE007.db.tree with 4996 entries\n",
      "Pat index with 4996 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYQ</SEQ></E>\\n<E><I\"\n",
      "Reading 23493 characters from file ./results_myria//sim_match_myriapod/DB/SE008.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE008.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE008.db.tree with 5022 entries\n",
      "Pat index with 5022 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYQ</SEQ></E>\\n<E><I\"\n",
      "Reading 24977 characters from file ./results_myria//sim_match_myriapod/DB/SE009.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE009.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE009.db.tree with 5110 entries\n",
      "Pat index with 5110 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYWGSLGTTGPTSNATDKG\"\n",
      "Reading 28457 characters from file ./results_myria//sim_match_myriapod/DB/SE010.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE010.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE010.db.tree with 5039 entries\n",
      "Pat index with 5039 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYPLYKPYMTRQG</SEQ>\"\n",
      "Reading 30398 characters from file ./results_myria//sim_match_myriapod/DB/SE011.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE011.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE011.db.tree with 5003 entries\n",
      "Pat index with 5003 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVVDDYGWIGEVRVTWVF\"\n",
      "Reading 28012 characters from file ./results_myria//sim_match_myriapod/DB/SE012.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE012.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE012.db.tree with 5068 entries\n",
      "Pat index with 5068 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYMKYTLIEIKARKWIEKS\"\n",
      "Reading 26980 characters from file ./results_myria//sim_match_myriapod/DB/SE013.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE013.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE013.db.tree with 5021 entries\n",
      "Pat index with 5021 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYQ</SEQ></E>\\n<E><I\"\n",
      "Reading 29464 characters from file ./results_myria//sim_match_myriapod/DB/SE014.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE014.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE014.db.tree with 5148 entries\n",
      "Pat index with 5148 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYYTTEK</SEQ></E>\\n<\"\n",
      "Reading 29701 characters from file ./results_myria//sim_match_myriapod/DB/SE015.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE015.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE015.db.tree with 5019 entries\n",
      "Pat index with 5019 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYQ</SEQ></E>\\n<E><I\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 31438 characters from file ./results_myria//sim_match_myriapod/DB/SE016.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE016.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE016.db.tree with 5011 entries\n",
      "Pat index with 5011 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYVYTKEETENNVYDLLDA\"\n",
      "Reading 33792 characters from file ./results_myria//sim_match_myriapod/DB/SE017.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE017.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE017.db.tree with 5099 entries\n",
      "Pat index with 5099 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYP</SEQ></E>\\n<E><I\"\n",
      "Reading 37125 characters from file ./results_myria//sim_match_myriapod/DB/SE018.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE018.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE018.db.tree with 5082 entries\n",
      "Pat index with 5082 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYNREACVYGLRIPALVFY\"\n",
      "Reading 24646 characters from file ./results_myria//sim_match_myriapod/DB/SE019.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE019.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE019.db.tree with 4977 entries\n",
      "Pat index with 4977 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYNLRTP</SEQ></E>\\n<\"\n",
      "Reading 34291 characters from file ./results_myria//sim_match_myriapod/DB/SE020.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE020.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE020.db.tree with 5130 entries\n",
      "Pat index with 5130 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYNKKQCIAGLRLPALVVY\"\n",
      "Reading 33910 characters from file ./results_myria//sim_match_myriapod/DB/SE021.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE021.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE021.db.tree with 4984 entries\n",
      "Pat index with 4984 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYYPVVYDQERSDY</SEQ\"\n",
      "Reading 31239 characters from file ./results_myria//sim_match_myriapod/DB/SE022.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE022.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE022.db.tree with 5041 entries\n",
      "Pat index with 5041 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYPMFKPYMTLQG</SEQ>\"\n",
      "Reading 39878 characters from file ./results_myria//sim_match_myriapod/DB/SE023.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE023.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE023.db.tree with 5092 entries\n",
      "Pat index with 5092 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYILELL</SEQ></E>\\n<\"\n",
      "Reading 36475 characters from file ./results_myria//sim_match_myriapod/DB/SE024.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE024.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE024.db.tree with 4972 entries\n",
      "Pat index with 4972 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYQVDGSFVPLYEDQCPIS\"\n",
      "Reading 32174 characters from file ./results_myria//sim_match_myriapod/DB/SE025.db\n",
      "Pre-processing input (peptides)\n",
      "100 sequences within 100 entries considered\n",
      "Creating file ./results_myria//sim_match_myriapod/DB/SE025.db.map for mapping\n",
      "Building new Pat index in file ./results_myria//sim_match_myriapod/DB/SE025.db.tree with 5142 entries\n",
      "Pat index with 5142 entries\n",
      " sorted, from \"A</SEQ></E>\\n<E><ID>\" to \"YYYTTEK</SEQ></E>\\n<\"\n",
      "\n",
      "\n",
      ".fasta files written...\n",
      "\n",
      "\n",
      "...genome DBs saved.\n",
      "\n",
      "   simulation finished!\n",
      "\n",
      "\n",
      "synthetic evolution completed in 0.12 minutes!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!alfsim alf-params_myria.drw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative additional steps would be to do the re-alignment of the simulated sequences here\n",
    "\n",
    "The individual gene sequences are in DB output folder from ALF\n",
    "\n",
    "Could realign with MAFFT (follow tutorial from Christophe: https://zoo.cs.ucl.ac.uk/tutorials/tutorial_treebuilding.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO, AlignIO\n",
    "import os\n",
    "from zoo.seq_utils import concatenate\n",
    "from zoo.wrappers.aligners import Mafft\n",
    "from zoo.wrappers.treebuilders import Phyml\n",
    "from zoo.wrappers.treebuilders import Raxml\n",
    "# regular expression needed to extract species name prior to concatenation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input_seq_dir = 'results_lopho/sim_match_lophotroch/DB'\n",
    "## aligned_seq_dir = 'test'\n",
    "## \n",
    "## for file in os.listdir(input_seq_dir):\n",
    "##     if file.endswith(\".fa\"):\n",
    "##         seq = list(SeqIO.parse(input_seq_dir+'/'+file, \"fasta\"))\n",
    "##         if len(seq) > 3:\n",
    "##             aligner = Mafft(seq, datatype='PROTEIN')\n",
    "##             msa = aligner()\n",
    "##             # store aligned sequences\n",
    "##             AlignIO.write(msa, aligned_seq_dir+'/'+file, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate MSAs in sets of 10, 20, 40, and 80 genes (out of the 100 simulated)\n",
    "\n",
    "For now using the true alignments (MSA output folder from ALF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aligned_seq_dir_lopho = 'results_lopho/sim_match_lophotroch/MSA'\n",
    "## aligned_seq_dir_myria = 'results_myria/sim_match_myriapod/MSA'\n",
    "\n",
    "\n",
    "## FOLLOWING the treebuilding tutorial doesn't work, fasta files must be in a different format\n",
    "## # take the alignments and concatenate\n",
    "## msaArrayLopho = []\n",
    "## msaArrayMyria = []\n",
    "\n",
    "## for file in os.listdir(aligned_seq_dir_lopho):\n",
    "##     if file.endswith(\".fa\"):\n",
    "##         alignment = AlignIO.read(aligned_seq_dir_lopho+'/'+file, \"fasta\")\n",
    "##         for s in alignment:\n",
    "## #            print(s)\n",
    "##             ###res = re.findall(r\"\\[(\\w{5})\\]\",s.description)  \n",
    "##             ## THIS DOES NOT WORK, should find why, maybe deprecated\n",
    "##             res = re.findall(r\"(\\w{4})\",s.description)\n",
    "##             if len(res) == 0:\n",
    "##                 raise RuntimeError(\"Can't find species name in seq \"+s.description+\" (\"+file+\")\")\n",
    "##             s.id = res[0] \n",
    "##              # orig from Christophe was -1, which would have made all species IDs as 0010, instead I \n",
    "##              # take the first chunk of res which should be the species ID\n",
    "## #            print(s.id)\n",
    "##         msaArrayLopho.append(alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate 10, 20, 40, or 80 genes\n",
    "\n",
    "!./ConcatenateGenes_MSAs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition (or don't) the subampled (or full) output MSAs from the simulations\n",
    "\n",
    "- run PartitionFinder2\n",
    "- needs anaconda bc it runs on an old version of Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: 'U' mode is deprecated\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# convert .fa to .phylip for partition finder 2\n",
    "\n",
    "import glob, os\n",
    "from Bio import AlignIO\n",
    "\n",
    "FOLDER = 'sampledMSAs'\n",
    "\n",
    "for f in glob.glob(os.path.join(FOLDER, '*.fa')):\n",
    "    input_handle = open(f, \"rU\")\n",
    "    output_handle = open(f.replace('fa','phy'), \"w\")\n",
    "\n",
    "    align = AlignIO.read(input_handle, \"fasta\")\n",
    "    AlignIO.write(align, output_handle, \"phylip-sequential\")\n",
    "\n",
    "    output_handle.close()\n",
    "    input_handle.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a space between species ID and bases in the sequential Phylip format\n",
    "\n",
    "!./ReformatPhylip.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a script I set up to go in the command line so that I can run python2.7 for PartitionFinder2\n",
    "\n",
    "!./PartitionMSAs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the trees from the partitioned (or not partitioned) results\n",
    "\n",
    "- run IQtree\n",
    "- run RaxML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use the zoo wrappers for this step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the original simulated (true) trees to the inferred trees that were partitioned or not\n",
    "\n",
    "- use Robinson Foulds distance\n",
    "- use Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeremy's RF calculation script\n",
    "\"\"\"\n",
    "Calculates RF distances between two trees\n",
    "\"\"\"\n",
    "\n",
    "from ete3 import Tree\n",
    "\n",
    "def collapse_branches(TREE_FILE,SUPPORT_THRESHOLD):\n",
    "    t = Tree(TREE_FILE)\n",
    "    for node in t.get_descendants():\n",
    "        if not node.is_leaf() and (node.support <= SUPPORT_THRESHOLD):\n",
    "            node.delete()\n",
    "    return t\n",
    "\n",
    "\n",
    "def count_internal(tree):\n",
    "    tree.unroot()\n",
    "    edges=-1\n",
    "    for edge in tree.traverse():\n",
    "        if not edge.is_leaf():\n",
    "            edges+=1\n",
    "    return edges\n",
    "\n",
    "def rf_distance(tree1,tree2,option=False):\n",
    "    if option=='collapse':\n",
    "        t1 = collapse_branches(tree1,0.75)\n",
    "        t2 = collapse_branches(tree2,0.75)\n",
    "        option = 'reduced'\n",
    "    else:\n",
    "        t1 = tree1 #Tree(tree1)\n",
    "        t2 = tree2 #Tree(tree2)\n",
    "\n",
    "    t1.unroot()\n",
    "    t2.unroot()\n",
    "\n",
    "    rf = t1.robinson_foulds(t2,unrooted_trees=True)\n",
    "\n",
    "    rf_dist = rf[0]\n",
    "    max_rf = rf[1]\n",
    "    num_leaves=len(rf[2])\n",
    "\n",
    "    max_resolved_score = (2*num_leaves)-6\n",
    "\n",
    "    internal_branches_t1 = count_internal(t1)\n",
    "    internal_branches_t2 = count_internal(t2)\n",
    "\n",
    "    total_internal = internal_branches_t1 + internal_branches_t2\n",
    "\n",
    "    num_missing_splits_t1 = num_leaves - 3 - internal_branches_t1\n",
    "    num_missing_splits_t2 = num_leaves - 3 - internal_branches_t2\n",
    "\n",
    "\n",
    "\n",
    "    rf_dist_upper = rf_dist + num_missing_splits_t1 + num_missing_splits_t2\n",
    "\n",
    "\n",
    "    #If normalise by (num intenral branches)\n",
    "    if option=='reduced':\n",
    "        normalised_rf = rf_dist/total_internal\n",
    "\n",
    "    elif option=='upper':\n",
    "    #If add score to create upper bound due to being polytomy\n",
    "        normalised_rf = rf_dist_upper/max_resolved_score\n",
    "    else:\n",
    "        normalised_rf = rf_dist/max_resolved_score\n",
    "\n",
    "    return normalised_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean distance calculation\n",
    "import dendropy\n",
    "from dendropy import Tree\n",
    "from dendropy.calculate import treecompare\n",
    "#ass_tree = Tree\n",
    "#ass_tree = ass_tree.get_from_string(ass_etree.write(),\"newick\",taxon_namespace=tns)\n",
    "#ref_tree = Tree()\n",
    "#ref_tree = ref_tree.get_from_string(ref_etree.write(),\"newick\",taxon_namespace=tns)\n",
    "#treecompare.euclidean_distance(ass_tree, ref_tree)\n",
    "#tns = dendropy.TaxonNamespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  /-S001_00001\n",
      "               /-|\n",
      "            /-|   \\-S036_00001\n",
      "           |  |\n",
      "           |   \\-S028_00001\n",
      "           |\n",
      "           |               /-S009_00001\n",
      "           |            /-|\n",
      "           |           |   \\-S043_00001\n",
      "           |         /-|\n",
      "           |        |  |   /-S021_00001\n",
      "         /-|      /-|   \\-|\n",
      "        |  |     |  |      \\-S046_00001\n",
      "        |  |     |  |\n",
      "        |  |     |   \\-S018_00001\n",
      "        |  |   /-|\n",
      "        |  |  |  |      /-S016_00001\n",
      "        |  |  |  |   /-|\n",
      "        |  |  |  |  |   \\-S037_00001\n",
      "        |  |  |   \\-|\n",
      "        |   \\-|     |      /-S022_00001\n",
      "        |     |     |   /-|\n",
      "        |     |      \\-|   \\-S052_00001\n",
      "        |     |        |\n",
      "        |     |         \\-S035_00001\n",
      "        |     |\n",
      "        |      \\-S010_00001\n",
      "        |\n",
      "        |               /-S004_00001\n",
      "        |            /-|\n",
      "        |         /-|   \\-S026_00001\n",
      "        |        |  |\n",
      "        |      /-|   \\-S011_00001\n",
      "        |     |  |\n",
      "        |     |   \\-S008_00001\n",
      "      /-|     |\n",
      "     |  |   /-|         /-S006_00001\n",
      "     |  |  |  |      /-|\n",
      "     |  |  |  |   /-|   \\-S054_00001\n",
      "     |  |  |  |  |  |\n",
      "     |  |  |   \\-|   \\-S034_00001\n",
      "     |  |  |     |\n",
      "     |  |  |     |   /-S032_00001\n",
      "     |  |  |      \\-|\n",
      "     |  |  |        |   /-S041_00001\n",
      "     |  |  |         \\-|\n",
      "     |  |  |           |   /-S042_00001\n",
      "     |  |  |            \\-|\n",
      "     |  |  |              |   /-S045_00001\n",
      "     |  |  |               \\-|\n",
      "     |  |  |                  \\-S056_00001\n",
      "     |  |  |\n",
      "     |  |  |                           /-S005_00001\n",
      "     |  |  |                        /-|\n",
      "     |  |  |                       |  |   /-S039_00001\n",
      "     |  |  |                       |   \\-|\n",
      "     |  |  |                     /-|      \\-S050_00001\n",
      "     |  |  |                    |  |\n",
      "     |  |  |                    |  |   /-S033_00001\n",
      "     |  |  |                  /-|   \\-|\n",
      "     |   \\-|                 |  |      \\-S051_00001\n",
      "     |     |               /-|  |\n",
      "     |     |              |  |   \\-S031_00001\n",
      "     |     |              |  |\n",
      "     |     |            /-|   \\-S030_00001\n",
      "     |     |           |  |\n",
      "     |     |           |  |   /-S029_00001\n",
      "     |     |         /-|   \\-|\n",
      "   /-|     |        |  |      \\-S060_00001\n",
      "  |  |     |        |  |\n",
      "  |  |     |        |  |   /-S023_00001\n",
      "  |  |     |        |   \\-|\n",
      "  |  |     |      /-|     |   /-S024_00001\n",
      "  |  |     |     |  |      \\-|\n",
      "  |  |     |     |  |         \\-S047_00001\n",
      "  |  |     |     |  |\n",
      "  |  |     |     |  |   /-S015_00001\n",
      "  |  |     |   /-|   \\-|\n",
      "  |  |     |  |  |      \\-S059_00001\n",
      "  |  |     |  |  |\n",
      "  |  |     |  |  |      /-S014_00001\n",
      "  |  |     |  |  |   /-|\n",
      "  |  |     |  |  |  |   \\-S044_00001\n",
      "  |  |     |  |   \\-|\n",
      "  |  |     |  |     |   /-S019_00001\n",
      "  |  |      \\-|      \\-|\n",
      "  |  |        |        |   /-S025_00001\n",
      "  |  |        |         \\-|\n",
      "  |  |        |           |   /-S048_00001\n",
      "  |  |        |            \\-|\n",
      "  |  |        |               \\-S049_00001\n",
      "  |  |        |\n",
      "  |  |        |   /-S007_00001\n",
      "--|  |         \\-|\n",
      "  |  |            \\-S017_00001\n",
      "  |  |\n",
      "  |  |      /-S003_00001\n",
      "  |  |   /-|\n",
      "  |  |  |  |   /-S040_00001\n",
      "  |  |  |   \\-|\n",
      "  |  |  |     |   /-S053_00001\n",
      "  |  |  |      \\-|\n",
      "  |   \\-|        |   /-S055_00001\n",
      "  |     |         \\-|\n",
      "  |     |            \\-S057_00001\n",
      "  |     |\n",
      "  |     |      /-S013_00001\n",
      "  |     |   /-|\n",
      "  |      \\-|   \\-S062_00001\n",
      "  |        |\n",
      "  |         \\-S061_00001\n",
      "  |\n",
      "  |         /-S002_00001\n",
      "  |      /-|\n",
      "  |     |   \\-S027_00001\n",
      "  |   /-|\n",
      "  |  |  |   /-S020_00001\n",
      "  |  |   \\-|\n",
      "   \\-|      \\-S038_00001\n",
      "     |\n",
      "     |   /-S012_00001\n",
      "      \\-|\n",
      "         \\-S058_00001\n"
     ]
    }
   ],
   "source": [
    "#real_tree = Tree(\"results_lopho/sim_match_lophotroch/RealTree.nwk\")\n",
    "#print(real_tree)\n",
    "\n",
    "real_tree = Tree(\"AnalysisResults/modified_RealTree.nwk\")\n",
    "print(real_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the trees\n",
    "\n",
    "\n",
    "# first load them all in\n",
    "#with open('iqtree.nw', 'w') as f:\n",
    "#    print(iq_res['tree'], \";\", file=f)\n",
    "\n",
    "\n",
    "    \n",
    "##real_tree = Tree(\"results_lopho/sim_match_lophotroch/RealTree.nwk\")\n",
    "inferred_tree_partAIC_rclust = Tree(\"AnalysisResults/tree_rcluster_AIC_part.nwk\")\n",
    "inferred_tree_partAICc_rclust = Tree(\"AnalysisResults/tree_rcluster_AICc_part.nwk\")\n",
    "inferred_tree_partBIC_rclust = Tree(\"AnalysisResults/tree_rcluster_BIC_part.nwk\")\n",
    "\n",
    "inferred_tree_partAIC_greedy = Tree(\"AnalysisResults/tree_greedyAIC_part.nwk\")\n",
    "inferred_tree_partAICc_greedy = Tree(\"AnalysisResults/tree_greedyAICc_part.nwk\")\n",
    "inferred_tree_partBIC_greedy = Tree(\"AnalysisResults/tree_greedyBIC_part.nwk\")\n",
    "\n",
    "inferred_tree_noPart = Tree(\"AnalysisResults/tree_noPart.nwk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0847457627118644"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare RF distance\n",
    "rf_distance(real_tree, inferred_tree_partAIC_rclust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0847457627118644"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare RF distance\n",
    "rf_distance(real_tree, inferred_tree_partAICc_rclust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0847457627118644"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare RF distance\n",
    "rf_distance(real_tree, inferred_tree_partBIC_rclust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0847457627118644"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare RF distance\n",
    "rf_distance(real_tree, inferred_tree_partAIC_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0847457627118644"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare RF distance\n",
    "rf_distance(real_tree, inferred_tree_partAICc_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0847457627118644"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare RF distance\n",
    "rf_distance(real_tree, inferred_tree_partBIC_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0847457627118644"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare RF distance\n",
    "rf_distance(real_tree, inferred_tree_noPart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf dist, max rf, num leaves\n",
      "10\n",
      "118\n",
      "62\n",
      "max resolved score\n",
      "118\n",
      "internal branches t1, t2\n",
      "59\n",
      "59\n",
      "total internal branches\n",
      "118\n",
      "missing splits t1, t2\n",
      "0\n",
      "0\n",
      "rf_dist_upper\n",
      "10\n",
      "normalised rf\n",
      "0.0847457627118644\n"
     ]
    }
   ],
   "source": [
    "# compare RF distance\n",
    "##rf_distance(real_tree, inferred_tree_noPart)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#rf = real_tree.robinson_foulds(inferred_tree_noPart,unrooted_trees=True)\n",
    "rf = real_tree.robinson_foulds(inferred_tree_partBIC_greedy,unrooted_trees=True)\n",
    "\n",
    "\n",
    "rf_dist = rf[0]\n",
    "max_rf = rf[1]\n",
    "num_leaves=len(rf[2])\n",
    "print(\"rf dist, max rf, num leaves\")\n",
    "print(rf_dist)\n",
    "print(max_rf)\n",
    "print(num_leaves)\n",
    "\n",
    "max_resolved_score = (2*num_leaves)-6\n",
    "print(\"max resolved score\")\n",
    "print(max_resolved_score)\n",
    "\n",
    "internal_branches_t1 = count_internal(real_tree)\n",
    "internal_branches_t2 = count_internal(inferred_tree_noPart)\n",
    "print(\"internal branches t1, t2\")\n",
    "print(internal_branches_t1)\n",
    "print(internal_branches_t1)\n",
    "\n",
    "total_internal = internal_branches_t1 + internal_branches_t2\n",
    "print(\"total internal branches\")\n",
    "print(total_internal)\n",
    "\n",
    "num_missing_splits_t1 = num_leaves - 3 - internal_branches_t1\n",
    "num_missing_splits_t2 = num_leaves - 3 - internal_branches_t2\n",
    "\n",
    "print(\"missing splits t1, t2\")\n",
    "print(num_missing_splits_t1)\n",
    "print(num_missing_splits_t2)\n",
    "\n",
    "\n",
    "rf_dist_upper = rf_dist + num_missing_splits_t1 + num_missing_splits_t2\n",
    "\n",
    "print(\"rf_dist_upper\")\n",
    "print(rf_dist_upper)\n",
    "\n",
    "normalised_rf = rf_dist/max_resolved_score\n",
    "\n",
    "print(\"normalised rf\")\n",
    "print(normalised_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, set(), set(), set(), set(), set()]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ete3 import Tree\n",
    "t1 = real_tree\n",
    "t2 = inferred_tree_noPart\n",
    "#rf, max_rf, common_leaves, parts_t1, parts_t2 = t1.robinson_foulds(t2)\n",
    "t1.robinson_foulds(t2, unrooted_trees=True)\n",
    "\n",
    "#print( t1, t2 )\n",
    "#print(\"RF distance is %s over a total of %s\" %(rf, max_rf))\n",
    "#print(\"Partitions in tree2 that were not found in tree1:\", parts_t1 - parts_t2)\n",
    "#print(\"Partitions in tree1 that were not found in tree2:\", parts_t2 - parts_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 6,\n",
       " {'a', 'b', 'c', 'e', 'f', 'g'},\n",
       " {((), ('a', 'b', 'c', 'e', 'f', 'g')),\n",
       "  (('a',), ('b', 'c', 'e', 'f', 'g')),\n",
       "  (('a', 'b'), ('c', 'e', 'f', 'g')),\n",
       "  (('a', 'b', 'c'), ('e', 'f', 'g')),\n",
       "  (('a', 'b', 'c', 'e', 'f'), ('g',)),\n",
       "  (('a', 'b', 'c', 'e', 'g'), ('f',)),\n",
       "  (('a', 'b', 'c', 'f', 'g'), ('e',)),\n",
       "  (('a', 'b', 'c', 'g'), ('e', 'f')),\n",
       "  (('a', 'b', 'e', 'f', 'g'), ('c',)),\n",
       "  (('a', 'c', 'e', 'f', 'g'), ('b',))},\n",
       " {((), ('a', 'b', 'c', 'e', 'f', 'g')),\n",
       "  (('a',), ('b', 'c', 'e', 'f', 'g')),\n",
       "  (('a', 'b', 'c'), ('e', 'f', 'g')),\n",
       "  (('a', 'b', 'c', 'e', 'f'), ('g',)),\n",
       "  (('a', 'b', 'c', 'e', 'g'), ('f',)),\n",
       "  (('a', 'b', 'c', 'f', 'g'), ('e',)),\n",
       "  (('a', 'b', 'c', 'g'), ('e', 'f')),\n",
       "  (('a', 'b', 'e', 'f', 'g'), ('c',)),\n",
       "  (('a', 'c'), ('b', 'e', 'f', 'g')),\n",
       "  (('a', 'c', 'e', 'f', 'g'), ('b',))},\n",
       " set(),\n",
       " set()]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = Tree('(((a,b),c), ((e, f), g));')\n",
    "t2 = Tree('(((a,c),b), ((e, f), g));')\n",
    "rf, max_rf, common_leaves, parts_t1, parts_t2, unknownset1, unknownset2 = t1.robinson_foulds(t2)\n",
    "t1.robinson_foulds(t2, unrooted_trees=True)\n",
    "\n",
    "#print( t1, t2 )\n",
    "#print(\"RF distance is %s over a total of %s\" %(rf, max_rf))\n",
    "#print(\"Partitions in tree2 that were not found in tree1:\", parts_t1 - parts_t2)\n",
    "#print(\"Partitions in tree1 that were not found in tree2:\", parts_t2 - parts_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 set() set() set() set() set()\n"
     ]
    }
   ],
   "source": [
    "t1 = Tree('((((((SE001:6.763867,SE036:9.018237):18.390485,SE028:30.072674):81.097267,(((((SE009:37.453273,SE043:15.184121):51.010313,(SE021:13.791936,SE046:15.109909):55.325145):25.645696,SE018:77.055289):1.3901876,((SE016:23.848119,SE037:19.220716):40.81827,((SE022:4.7044425,SE052:4.1592241):23.674158,SE035:16.949675):39.883503):27.169764):20.633608,SE010:114.80186):11.350097):22.72556,(((((SE004:40.148165,SE026:32.760152):57.046485,SE011:124.9786):14.993695,SE008:111.873):15.676894,(((SE006:9.8134579,SE054:8.2849921):30.258867,SE034:65.462813):3.5185959,(SE032:51.996378,(SE041:29.836225,(SE042:12.915469,(SE045:6.449729,SE056:6.3520307):14.308106):4.1242536):7.2325794):11.948603):108.13093):2.7134997,(((((((((SE005:28.52028,(SE039:13.34738,SE050:23.424806):19.588144):9.0171402,(SE033:2.441533,SE051:2.1236517):30.612518):2.7455399,SE031:33.840353):4.9687643,SE030:78.88561):0.77401156,(SE029:23.412266,SE060:11.544024):54.783893):20.909054,(SE023:61.644961,(SE024:13.318505,SE047:8.4328913):53.104084):1.5038578):38.329347,(SE015:13.171844,SE059:15.861024):109.54711):0.72431622,((SE014:2.5002962,SE044:5.1339748):73.534429,(SE019:47.212151,(SE025:4.5543526,(SE048:5.1859649,SE049:4.0775825):0.11842907):50.903656):28.806912):14.519452):38.888934,(SE007:192.13188,SE017:83.194949):47.95616):5.3529357):1.7729805):0.20241253,((SE003:71.935167,(SE040:17.390151,(SE053:13.506231,(SE055:12.77371,SE057:21.647035):4.7295572):1.0344563):21.627671):81.690822,((SE013:35.75813,SE062:24.23892):7.0698314,SE061:30.777494):120.26528):42.651013):2.583634,(((SE002:33.348348,SE027:55.026316):27.695845,(SE020:33.124321,SE038:23.960994):49.153206):32.01939,(SE012:45.713315,SE058:42.753672):109.94672):44.704874):0;')\n",
    "t2 = Tree('(S001_00001:0.0434319065,(((((((S002_00001:0.3697369943,S027_00001:0.6126559436)100:0.3388700497,(S020_00001:0.3550410352,S038_00001:0.2409323159)100:0.4384678807)99:0.1934624237,(S012_00001:0.5003663599,S058_00001:0.3883462728)100:1.0331248890)100:0.5430729522,((((S003_00001:0.7689984284,(S040_00001:0.1578675658,(S053_00001:0.1496365107,(S055_00001:0.1378594099,S057_00001:0.2219459169)99:0.0348115431)95:0.0267652270)98:0.1776109973)100:0.8003386724,((S013_00001:0.3899535599,S062_00001:0.2942007319)89:0.0280468912,S061_00001:0.3443671493)100:1.2473656470)99:0.3947120620,(((S004_00001:0.3627906023,S026_00001:0.3762137365)100:0.5419273026,S011_00001:1.3758795447)97:0.1758283613,S008_00001:1.1520474927)95:0.2029315772)64:0.0450659329,(((((((((S005_00001:0.2918875754,(S039_00001:0.1228984534,S050_00001:0.2213151258)100:0.1383150073)100:0.0837400751,(S033_00001:0.0257719713,S051_00001:0.0161293331)100:0.3355927000)99:0.0531193670,S031_00001:0.3847208060)99:0.0726858364,S030_00001:0.7672930487)74:0.0036085376,(S029_00001:0.2613801747,S060_00001:0.1185887308)100:0.6167549217)100:0.1758704900,(S023_00001:0.6470199396,(S024_00001:0.1147516862,S047_00001:0.0640477665)100:0.4849678333)90:0.0641417947)100:0.3758366130,(S015_00001:0.1297565568,S059_00001:0.1644313005)100:1.0451349440)81:0.0295069069,((S014_00001:0.0634125484,S044_00001:0.0116458740)100:0.7783007854,(S019_00001:0.4965275139,((S025_00001:0.0317229312,S048_00001:0.0457952787)99:0.0048986126,S049_00001:0.0273059076)100:0.4658208483)100:0.2578159861)97:0.1182469930)100:0.3627525660,(S007_00001:2.0431021365,S017_00001:1.0917588279)98:0.3557731841)69:0.0676630231)21:0.0000022639)41:0.0128655358,(((S006_00001:0.1209407007,S054_00001:0.0700651539)100:0.2886222622,S034_00001:0.6147863303)95:0.0741641655,(S032_00001:0.5669289633,(S041_00001:0.3184170237,(S042_00001:0.1383473782,(S045_00001:0.0564010284,S056_00001:0.0515258023)100:0.1459628406)96:0.0071249282)98:0.0505763096)99:0.1355056294)100:1.2451706690)100:0.2881994824,((((S009_00001:0.3489712302,S043_00001:0.1256459583)100:0.5501793789,(S021_00001:0.1863024433,S046_00001:0.1428584496)100:0.4460892835)100:0.2644491608,(((S016_00001:0.2804604843,S037_00001:0.1365145846)100:0.4688962936,((S022_00001:0.0597641443,S052_00001:0.0480989133)100:0.2572527576,S035_00001:0.1531712734)100:0.4061384993)100:0.3317962604,S018_00001:0.7587740841)78:0.0222089697)99:0.1725110770,S010_00001:1.1125582706)95:0.1271616960)100:0.7808798021,S028_00001:0.2813453204)100:0.1824209024,S036_00001:0.0977687561);')\n",
    "rf, max_rf, common_leaves, parts_t1, parts_t2, unknownset1, unknownset2 = t1.robinson_foulds(t2, unrooted_trees=True)\n",
    "#t1.robinson_foulds(t2, unrooted_trees=True)\n",
    "\n",
    "print(rf, max_rf, common_leaves, parts_t1, parts_t2, unknownset1, unknownset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare Euclidean distance\n",
    "# ref_tree = real_tree.get_from_path(real_etree.write(AnalysisResults/modified_RealTree.nwk),\"newick\",taxon_namespace=tns)\n",
    "#comp_tree = inferred_tree_partAIC_rclust.get_from_string(inferred_etree_partAIC_rclust.write(),\"newick\",taxon_namespace=tns)\n",
    "\n",
    "#treecompare.euclidean_distance(real_tree, inferred_tree_partAIC_rclust)\n",
    "\n",
    "#treecompare.euclidean_distance(ref_tree, comp_tree)\n",
    "#tns = dendropy.TaxonNamespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498.1758378443058\n"
     ]
    }
   ],
   "source": [
    "import dendropy\n",
    "from dendropy import Tree as tree\n",
    "from dendropy.calculate import treecompare\n",
    "\n",
    "tns = dendropy.TaxonNamespace()\n",
    "\n",
    "tree1 = tree.get_from_path(\n",
    "        \"AnalysisResults/modified_RealTree.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "\n",
    "tree2 = tree.get_from_path(\n",
    "        \"AnalysisResults/tree_noPart.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "tree1.encode_bipartitions()\n",
    "tree2.encode_bipartitions()\n",
    "print(treecompare.euclidean_distance(tree1, tree2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498.1729185398443\n"
     ]
    }
   ],
   "source": [
    "tree1 = tree.get_from_path(\n",
    "        \"AnalysisResults/modified_RealTree.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "\n",
    "tree2 = tree.get_from_path(\n",
    "        \"AnalysisResults/tree_rcluster_AIC_part.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "tree1.encode_bipartitions()\n",
    "tree2.encode_bipartitions()\n",
    "print(treecompare.euclidean_distance(tree1, tree2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498.17346684526217\n"
     ]
    }
   ],
   "source": [
    "tree1 = tree.get_from_path(\n",
    "        \"AnalysisResults/modified_RealTree.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "\n",
    "tree2 = tree.get_from_path(\n",
    "        \"AnalysisResults/tree_rcluster_AICc_part.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "tree1.encode_bipartitions()\n",
    "tree2.encode_bipartitions()\n",
    "print(treecompare.euclidean_distance(tree1, tree2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498.1721147408412\n"
     ]
    }
   ],
   "source": [
    "tree1 = tree.get_from_path(\n",
    "        \"AnalysisResults/modified_RealTree.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "\n",
    "tree2 = tree.get_from_path(\n",
    "        \"AnalysisResults/tree_rcluster_BIC_part.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "tree1.encode_bipartitions()\n",
    "tree2.encode_bipartitions()\n",
    "print(treecompare.euclidean_distance(tree1, tree2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498.1721147408412\n"
     ]
    }
   ],
   "source": [
    "tree1 = tree.get_from_path(\n",
    "        \"AnalysisResults/modified_RealTree.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "\n",
    "tree2 = tree.get_from_path(\n",
    "        \"AnalysisResults/tree_greedyAIC_part.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "tree1.encode_bipartitions()\n",
    "tree2.encode_bipartitions()\n",
    "print(treecompare.euclidean_distance(tree1, tree2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498.16853197394056\n"
     ]
    }
   ],
   "source": [
    "tree1 = tree.get_from_path(\n",
    "        \"AnalysisResults/modified_RealTree.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "\n",
    "tree2 = tree.get_from_path(\n",
    "        \"AnalysisResults/tree_greedyAICc_part.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "tree1.encode_bipartitions()\n",
    "tree2.encode_bipartitions()\n",
    "print(treecompare.euclidean_distance(tree1, tree2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498.1586883819632\n"
     ]
    }
   ],
   "source": [
    "tree1 = tree.get_from_path(\n",
    "        \"AnalysisResults/modified_RealTree.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "\n",
    "tree2 = tree.get_from_path(\n",
    "        \"AnalysisResults/tree_greedyBIC_part.nwk\",\n",
    "        \"newick\", taxon_namespace=tns)\n",
    "tree1.encode_bipartitions()\n",
    "tree2.encode_bipartitions()\n",
    "print(treecompare.euclidean_distance(tree1, tree2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tree_list = dendropy.TreeList()\n",
    "# tree_list.read(data=tree_str1, schema=\"newick\")\n",
    "# print(tree_list.taxon_namespace)\n",
    "# tree_list.read(data=tree_str1, schema=\"newick\")\n",
    "# print(tree_list.taxon_namespace)\n",
    "# for nd1, nd2 in zip(tree_list[0], tree_list[1]):\n",
    "#     assert nd1.taxon is nd2.taxon # OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is overfitting, we expect the partitioned trees to be no better matched to the true tree, or potentially even more poorly matched?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
